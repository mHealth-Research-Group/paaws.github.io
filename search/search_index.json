{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PAAWS Study","text":"<p>Welcome to the PAAWS Study documentation.</p> <p>This site provides comprehensive documentation for the PAAWS (Physical Activity and Wearable Sensors) dataset and study protocol. Use the navigation on the left to explore the different sections.</p>"},{"location":"codebook/","title":"The PAAWS Dataset Codebook","text":"<p>The PAAWS dataset consists of data from the PAAWS study in which there were three data collection protocols: the Simulated Free Living and Exercise Laboratory (SimFL+Lab) protocol, the Free Living (FL) protocol, and an optional Sleep protocol that took place during the FL protocol and provided labeled PSG data from up to two nights of at-home sleep. In this codebook, we discuss the data that resulted from each protocol, not how it was collected. To review each of the data collection protocols, refer to The PAAWS Study Data Collection Protocol.</p>"},{"location":"codebook/#overview-of-available-data-and-directory-structure","title":"Overview of Available Data and Directory Structure","text":"<p>The dataset is available at TODO. The dataset is organized firstly by collection protocol (e.g., FL, SimFL+Lab, or Sleep) and then by each participant's data for that protocol. All data from a single participant, labeled as DS_[ID], collected during a specific protocol, are stored within the respective protocol subfolder (summarized in Figure 1).</p>"},{"location":"codebook/#figure-1.-directory-structure-of-the-paaws-dataset.","title":"Figure 1. Directory structure of the PAAWS dataset.","text":"<p><code>PAAWS_dataset/</code> <code>\u251c\u2500\u2500 PAAWS_Data_Summary.csv</code> <code>\u251c\u2500\u2500 PAAWS_SimFL_Lab/</code> <code>\u2502   \u251c\u2500\u2500 DS_ID/</code> <code>\u2502   \u2502   \u251c\u2500\u2500 accel/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWristTop.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWristBottom.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistAnterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistMid.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistPosterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightThigh.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleAnterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleLateral.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnklePosterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleMedial.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWristTop.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWristBottom.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistAnterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistMid.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistPosterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftThigh.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleAnterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleLateral.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnklePosterior.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleMedial.csv</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-Phone.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 IMU/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWristTop-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWristBottom-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistAnterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistMid-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightWaistPosterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightThigh-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleAnterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleLateral-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnklePosterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-RightAnkleMedial-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWristTop-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWristBottom-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistAnterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistMid-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftWaistPosterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftThigh-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleAnterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleLateral-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnklePosterior-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LeftAnkleMedial-IMU.csv</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-Phone-IMU.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 MET/</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-MET.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 heart_rate/</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-HR.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 phone_data/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-AmbientPressManager.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-AppEventCounts.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-LightSensorStats.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-NotificationCounts.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-ProximitySensorManagerService.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Lab-StepCounterService.csv</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-Acceleration.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 label/</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Lab-label.csv</code> <code>\u2502   \u2502   \u2514\u2500\u2500 notes/</code> <code>\u2502   \u2502       \u251c\u2500\u2500 DS_ID-Lab-GeneralNote.txt</code> <code>\u2502   \u2502       \u2514\u2500\u2500 DS_ID-Lab-DeviationsFromProtocol.csv</code> <code>\u2502   \u2514\u2500\u2500 ...</code> <code>\u251c\u2500\u2500 PAAWS_FreeLiving/</code> <code>\u2502   \u251c\u2500\u2500 DS_ID/</code> <code>\u2502   \u2502   \u251c\u2500\u2500 accel/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-RightWrist.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-LeftWrist.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-RightThigh.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-RightAnkle.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-RightWaist.csv</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Free-Phone.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 phone_data/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-AmbientPressManager.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-AppEventCounts.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-LightSensorStats.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-NotificationCounts.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-ProximitySensorManagerService.csv</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-StepCounterService.csv</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Free-Acceleration.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 label/</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Free-label.csv</code> <code>\u2502   \u2502   \u251c\u2500\u2500 notes/</code> <code>\u2502   \u2502   \u2502   \u251c\u2500\u2500 DS_ID-Free-GeneralBehavior.txt</code> <code>\u2502   \u2502   \u2502   \u2514\u2500\u2500 DS_ID-Free-Recalls.csv</code> <code>|    \u2514\u2500\u2500 ...</code> <code>\u251c\u2500\u2500 PAAWS_sleep/</code> <code>\u2502   \u251c\u2500\u2500 DS_ID/</code> <code>\u2502   \u2502   \u251c\u2500\u2500 DS_ID-Sleep-Night1.edf</code> <code>\u2502   \u2502   \u2514\u2500\u2500 DS_ID-Sleep-Night2.edf</code> <code>\u2502   \u2502   \u2514\u2500\u2500 DS_ID-Sleep-Night1_scored_events.csv</code> <code>\u2502   \u2502   \u2514\u2500\u2500 DS_ID-Sleep-Night2_scored_events.csv</code> <code>\u2502   \u2514\u2500\u2500 ...</code></p>"},{"location":"codebook/#available-data-and-description-of-each-data-type","title":"Available Data and Description of Each Data Type","text":"<p>The PAAWS dataset contains raw measurements from multiple sets of sensors for each protocol and human-generated annotations of activity based on an activity taxonomy. </p> <p>For each participant (DS_ID/), the PAAWS_SimFL_Lab subfolder contains: </p> <ul> <li>accel/: a folder containing the Accelerometer data collected from twenty on-body and one on-phone ActiGraph GT9X Link sensors.  </li> <li>IMU/: a folder containing the inertial movement data collected from twenty on-body and one on-phone ActiGraph GT9X Link sensors.  </li> <li>MET/: a folder containing the data collected by the COSMED CPET indirect calorimeter for a subset of the activities in the SimFL+Lab protocol.  </li> <li>heart_rate/: a folder containing heart rate data collected from a Polar H10 heart rate monitor.  </li> <li>phone_data/: a folder containing data collected from participants\u2019 Android devices using a custom-built Android app. These data are only available if the participant owned a compatible Android phone.  </li> <li>labels/: a folder containing second-by-second annotations of the activities done during the SimFL+Lab protocol from third-person footage or, in instances when there was an issue with the third-person footage, front-facing egocentric camera.  </li> <li>notes/: a folder containing any notes on participant behavior and any deviations from the SimFL+Lab protocol.</li> </ul> <p>The PAAWS_FreeLiving subfolder contains:</p> <ul> <li>accel/: a folder containing the Accelerometer data collected from five on-body and one on-phone ActiGraph GT9X Link sensors.  </li> <li>phone_data/: a folder containing data collected from participants\u2019 Android devices using a custom-built Android app. These data are only available if the participant owned a compatible Android phone.  </li> <li>labels/: a folder containing second-by-second annotations of the activities done during the FL protocol from an egocentric front-facing camera.  </li> <li>notes/: a folder containing self-reported data on activity and sleep from daily recall sessions.</li> </ul> <p>For the participants who completed the Sleep protocols, the PAAWS_Sleep subfolder contains:</p> <ul> <li>Polysomnography (PSG) data from up to two nights collected using the Noxturnal A1 PSG system at home, during natural sleep  </li> <li>Wake/Sleep times, sleep stages, and other sleep-related events (described in Table 15) that are manually labeled by trained sleep researchers using the PSG data.</li> </ul>"},{"location":"codebook/#data-summary-table","title":"Data Summary Table","text":"<p>For users of the data curious about understanding demographics, available data, and potential issues with the data by participant, we provide a summary table of the dataset in the /PAAWS_Data_Summary.csv file. We define each column header and possible values in Table 1.</p>"},{"location":"codebook/#table-1.-column-headings-and-possible-values-in-the-paaws_data_summary.csv-file.","title":"Table 1. Column headings and possible values in the PAAWS_Data_Summary.csv file.","text":"Column Name Description (e.g., This field contains\u2026) Technical Note DATASET The name of the dataset/participant ID In the format DS_ID, where ID is a number between 10 and 305 (inclusive) AGE_RANGE The age range of the participant Can be 18-34, 35 - 55, or 55+ GENDER Gender of the participant Can either be <code>M</code> (for Male), <code>F</code> for Female, <code>TM</code> (for transgender male), <code>TF</code> (for transgender female), <code>NB</code> (for non gender-conforming), or <code>Other</code> (for other or non-disclosure) HEIGHT_CM Height, in centimeters WEIGHT_KG Weight, in kilograms LAB_SHOES Shoes the participant wore while doing the SimFL+Lab protocol Can be either <code>Athletic</code> (running shoes), <code>Boots</code> (hiking or fall boots), <code>Sneakers</code> (casual everyday shoes), or <code>Flipflops</code> (slippers or crocs) PREFERRED_WRITING_HAND Participant's preferred writing hand. Can be used as a proxy for the participant\u2019s dominant hand Can either be Left or Right PAAWS_SIMFL_LAB If the participant did the SimFL+Lab protocol Either Y or N LAB_ADDITIONAL_PHONE_USAGE If there is additional phone usage data in the SimFL+Lab protocol Either Y or N PAAWS_FREELIVING If the participant did the FL protocol Either Y or N FREELIVING_SENSOR_DAYS The number of days the participant spent in the PAAWS_FreeLiving protocol Range from 1-8 (days) FREELIVING_LABELED_DAYS The number of labelled days of data in the PAAWS_FreeLiving protocol Range from 1-8 (days). FREELIVING_ADDITIONAL_PHONE_USAGE If there is additional phone usage data in the FL protocol Either Y or N PAAWS_SLEEP The number of nights we collected additional sleep data from the participant as part of the Sleep protocol Either 0 (participant did not perform the Sleep protocol), 1, or 2 LAB_[SENSOR_LOCATION] If we know of any issues with the ActiGraph sensor in [SENSOR_LOCATION] for the SimFL+Lab protocol. The sensors worn during the SimFL+Lab protocol are documented in  SimFL+Lab Sensor Wear Location. Values are in the format <code>[Availability]/[Optional_Possible_Issues]</code> <code>[Availability]</code> can either be Y (have data) or N (no data available). In the case data is present but there were issues with the data, the <code>[Optional_Possible_Issues]</code> value can be: <code>Partial</code> (some data was missing), <code>Orientation</code> (sensor was not placed according to the specified orientation), or <code>Accelerometer_Only</code> (where the IMU data for this sensor was missing, possibly due to data corruption). FREE_[SENSOR_LOCATION] If we know of any issues with the ActiGraph sensor in [SENSOR_LOCATION] for the FL protocol. The sensors worn in the FL protocol are documented in FL Sensor Wear Location. Values are in the format <code>[Availability]/[Optional_Possible_Issues]</code> <code>[Availability]</code> can either be Y (have data) or N (no data available). In the case data are present but there were issues with the data, the <code>[Optional_Possible_Issues]</code> value can be: <code>Partial</code> (some data was missing), <code>Orientation</code> (sensor was not placed according to the specified orientation), or <code>Issue</code> (some other participant-specific issues which were documented separately in the participant\u2019s notes)."},{"location":"codebook/#_1","title":"Codebook","text":""},{"location":"codebook/#accelerometer-data","title":"Accelerometer Data","text":"<p>We collected accelerometer data using ActiGraph GT9X Link sensors sampling at 80 Hz. Accelerometer data from each sensor are stored in the <code>accel/</code> folder following the naming convention: <code>accel/DS_ID-[Free/Lab]-[SensorWearLocation].csv</code>. In the FL protocol, data were collected from six wear locations, and in the SimFL+Lab protocol, data were collected from 21 wear locations. Refer to The PAAWS Study Data Collection Protocol for detailed descriptions of sensor wear locations.</p> <p>We extracted the accelerometer data from each sensor from the raw GT3X file (a proprietary format by Actigraph) using ActiLife software. We provide accelerometer data in a CSV file with a ten-line header (Figure 2).</p>"},{"location":"codebook/#figure-2:-header-generated-by-actilife-software-for-all-accelerometer-data.","title":"Figure 2: Header generated by ActiLife software for all accelerometer data.","text":"<p><code>------------ Data File Created By ActiGraph GT3X+ ActiLife v6.X.X Firmware v1.X.X date format M/d/yyyy at 80 Hz  Filter Normal -----------</code> <code>Serial Number: TASXXXXXXXX</code> <code>Start Time HH:MM:SS</code> <code>Start Date M/d/yyyy</code> <code>Epoch Period (hh:mm:ss) 00:00:00</code> <code>Download Time HH:MM:SS</code> <code>Download Date M/d/yyyy</code> <code>Current Memory Address: 0</code> <code>Current Battery Voltage: 3.91     Mode = 12</code> <code>--------------------------------------------------</code></p> <p>The start time, start date, serial number, and download date fields (shown using red text) are sensor-specific (i.e., each sensor has a unique serial number, start date/time, and download date/time). The timestamps of each datapoint can be recovered from the data collection start time using the sampling rate. We provide a script to read accelerometer data into a DataFrame with timestamps in our git repository. After the header, each accelerometer data CSV file has three columns, corresponding to the acceleration in the three axes (Table 2). </p>"},{"location":"codebook/#table-2.-columns-in-the-accelerometer-data-file-(accel/ds_[id]-[lab/free]-[sensorlocation].csv).","title":"Table 2. Columns in the accelerometer data file (accel/DS_[ID]-[Lab/Free]-[SensorLocation].csv).","text":"Column name Description Technical note Accelerometer X Acceleration in the X axis A floating point number between -8 and 8. Unit is in g Accelerometer Y Acceleration in the Y axis A floating point number between -8 and 8. Unit is in g Accelerometer Z Acceleration in the Z axis A floating point number between -8 and 8. Unit is in g <p>During the data collection protocol, the sensor might be plugged into a docking station (for charging or debugging). When plugged in, the sensor is not collecting data. Accelerometer values for this time period are represented by consecutive rows of zero acceleration across all three axes (e.g., <code>0,0,0</code>). </p>"},{"location":"codebook/#partially-missing-accelerometer-data","title":"Partially missing accelerometer data","text":"<p>Because the FL protocol spans eight continuous days, a research assistant may have swapped a current sensor with a newer one if a sensor had an issue, such as dying due to battery drain. Swapping a sensor in the middle of the FL protocol may have resulted in some missing data. At the end of the FL protocol, a research assistant combined the data collected from the initial sensors with the swapped-in sensors (see The PAAWS Study Data Collection Protocol for details on syncing and merging data from different sensors). The result of this process yields an accelerometer file that might seem to have missing data in the case where one sensor died prematurely before the research assistant could swap the sensor. These missing data are documented in their respective <code>notes/</code> folders.</p> <p>Missing accelerometer data due to sensors not collecting any data are represented by \u201cblank\u201d lines with no accelerometer values and just two commas (e.g., \u201c,,\u201d as a line in the CSV).  </p>"},{"location":"codebook/#fully-missing-accelerometer-data","title":"Fully missing accelerometer data","text":"<p>In some cases, a malfunctioned sensor (e.g., due to a firmware or hardware error) did not collect any data. The entire accelerometer data stream from that sensor was lost, and we documented all such instances both in the data summary table and in the participants\u2019 notes file.</p>"},{"location":"codebook/#imu-data-(simfl+lab-only)","title":"IMU Data (SimFL+Lab Only)","text":"<p>While collecting accelerometer data at 80 HZ, we additionally collected IMU data at 100 Hz using the ActiGraph GT9X Link sensors. Because collecting the IMU drains the sensors batteries, IMU data were only collected during the PAAWS SimFL+Lab protocol. The IMU data collected from each sensor are stored in the <code>IMU/</code> folder following the naming convention: <code>IMU/DS_ID-Lab-[WearLocation]-IMU.csv</code>.  IMU data were collected from all 21 sensor wear locations in the SimFL+Lab protocol (see The PAAWS Study Data Collection Protocol).</p> <p>We extracted the IMU data from raw GT3X files using the R package AGRead. IMU data are provided in CSV format with a ten-line header following ActiGraph\u2019s specification (Figure 3).</p>"},{"location":"codebook/#figure-3:-header-generated-by-actilife-software-for-all-imu-data.","title":"Figure 3: Header generated by ActiLife software for all IMU data.","text":"<p><code>------------ Data File Created By ActiGraph Link IMU 9DOF Sensor ActiLife v6.X.X Firmware v1.X.X date format M/d/yyyy at 100 Hz -----------</code> <code>Serial Number: TASXXXXXXXXX</code> <code>Start Time HH:MM:SS</code> <code>Start Date M/d/yyyy</code> <code>Epoch Period (hh:mm:ss) 00:00:00</code> <code>Download Time HH:MM:SS</code> <code>Download Date M/d/yyyy</code> <code>Current Memory Address: 0</code> <code>Current Battery Voltage: 3.91 Mode = 12</code> <code>--------------------------------------------------</code></p> <p>Like the accelerometer data, the start time, start date, serial number, and download date fields (shown  in red text) are sensor-specific (i.e., each sensor has an unique serial number, start date/time, and download date/time). The timestamp of each datapoint can be recovered from the data collection start time and the sampling rate. We also provide a sample script to read IMU data into a DataFrame with timestamps in our git repository. After the header, each IMU data CSV file has ten columns (Table 3). </p>"},{"location":"codebook/#table-3.-columns-in-the-imu-data-file-(ds_id-lab-[sensorlocation]-imu.csv).","title":"Table 3. Columns in the IMU data file (DS_ID-Lab-[SensorLocation]-IMU.csv).","text":"Column name Description Technical note Accelerometer X Acceleration in the X axis A floating point number between -8 and 8. Unit is in g Accelerometer Y Acceleration in the Y axis A floating point number between -8 and 8. Unit is in g Accelerometer Z Acceleration in the Z axis A floating point number between -8 and 8. Unit is in g Temperature Ambient temperature A floating point number. Unit is in C Magnetometer X Strength of the magnetic field in the X axis A floating point number between -4800 and 4800. Unit is in micro-T Magnetometer Y Strength of the magnetic field in the Y axis A floating point number between -4800 and 4800. Unit is in micro-T Magnetometer Z Strength of the magnetic field in the Z axis A floating point number between -4800 and 4800. Unit is in micro-T Gyroscope X Speed of the rotation in the X axis A floating point number between -2000 and 2000. Unit is degree/sec Gyroscope Y Speed of the rotation in the Y axis A floating point number between -2000 and 2000. Unit is degree/sec Gyroscope Z Speed of the rotation in the Z axis A floating point number between -2000 and 2000. Unit is degree/sec"},{"location":"codebook/#missing-imu-data","title":"Missing IMU data","text":"<p>In some cases, a malfunctioned sensor (e.g., due to a firmware or hardware error) did not collect any data, or an incorrectly initialized sensor did not collect any IMU data. The entire IMU data stream from that sensor was lost, and we documented all such instances both in the data summary table and in the participants\u2019 notes file.</p>"},{"location":"codebook/#heart-rate-data-(simfl+lab-only)","title":"Heart Rate Data (SimFL+Lab Only)","text":"<p>During the SimFL+Lab protocol, we collected heart rate data using a Polar H10 heart rate monitor sampling at 1 Hz. Heart rate data are stored in the <code>heart_rate/</code> folder and follow the file naming convention /heart_rate/<code>DS_[ID]-Lab-HR.csv</code>. The HR data CSV for each participant has two columns (Table 4). </p> <p>We parsed the <code>DS_ID-Lab-HR.csv</code> file from the original raw AGD file (a proprietary format by Actigraph). We removed missing data (caused by a poor connection between the H10 sensor and a participant\u2019s skin or a poor connection to the GT9X link device that recorded the HR data). For 16 participants, the raw heart rate data were summarized in 60 s epochs instead of 1 s epochs due to a configuration error; these instances are documented in the data summary table and in each participant\u2019s note file.</p>"},{"location":"codebook/#_2","title":"Codebook","text":""},{"location":"codebook/#table-4.-columns-in-the-heart-rate-data-file-(ds_id-lab-hr.csv).","title":"Table 4. Columns in the heart rate data file (DS_ID-Lab-HR.csv).","text":"Column Name Description Technical Note Timestamp The timestamp when this heart rate is recorded Timestamp is in the format <code>YYYY-MM-DD HH:MM:SS</code> HR The heart rate A non-zero integer representing the number of heartbeats per minute"},{"location":"codebook/#metabolic-data-(simfl+lab-only)","title":"Metabolic Data (SimFL+Lab Only)","text":"<p>We collected metabolic data via the Cosmed Quark RMR CPET indirect calorimeter for a subset of activities performed during the SimFL+Lab protocol (see The PAAWS Study Data Collection Protocol). For each activity completed while wearing the metabolic mask, we calculated the metabolic equivalent of task (MET) from the raw data using the following formula:  MET \\= VO2(mL/min)3.5 (mL/kg/min)  Weight (kg). Metabolic data are stored in the /MET folder and follow the file name convention DS_[ID]-Lab-MET.csv. Each MET CSV file has three columns (Table 5).</p> <p>For each activity we collected metabolic data for, we asked participants to perform the activity long enough to achieve a steady state (each activity had an activity-specific value for how long this might take). In cases when the participant did not perform the activity long enough to achieve a steady state, MET data are missing. Additionally, some data is missing because the metabolic cart could not register breaths that were \u201ctoo faint\u201d or breaths that leaked outside the mask when the mask became loose.</p>"},{"location":"codebook/#table-5.-columns-in-the-metabolic-data-file-(ds_[id]-lab-met.csv).","title":"Table 5. Columns in the metabolic data file (DS_[ID]-Lab-MET.csv).","text":"Column Name Description Technical Note START_TIME Start time of the activity Time is a string in the format <code>YYYY-MM-DD HH:MM:SS</code> STOP_TIME Stop time of the activity Time is a string in the format <code>YYYY-MM-DD HH:MM:SS</code> PA_Type The activity performed The Annotation label taxonomy section describes the activities set performed with the indirect calorimeter Parsed_MET The average breath-by-breath metabolic value taken from the last minute of the activity A number"},{"location":"codebook/#phone-data","title":"Phone Data","text":"<p>Phone data were collected from participants who owned and used a compatible Android device as their personal phone; in such cases, a custom-built Android app was installed on the phone. The phone data includes data from the ambient pressure sensor, light sensor, proximity sensor, accelerometer sensor, data about phone usage (i.e., generic phone usage and notifications sent to the user), and hourly step counts obtained from the Android API.</p> <p>All data collected from the Android app is stored in the <code>phone_data/</code> folder. Phone data CSV files are named according to the data they contain and follow the structure <code>DS_ID-[Free/Lab]-[DATA_TYPE].csv</code>. </p>"},{"location":"codebook/#phone-data:-ambient-pressure-data","title":"Phone Data: Ambient Pressure Data","text":"<p>The Android phone\u2019s pressure sensor measured the ambient pressure. Data are provided in CSV format with the naming convention: <code>DS_ID-[Free/Lab]-AmbientPressureManager.csv</code>. Table 6 details the columns in this CSV file. </p>"},{"location":"codebook/#table-6.-columns-in-the-ambient-pressure-file-(ds_id-[free/lab]-ambientpressuremanager.csv).","title":"Table 6. Columns in the ambient pressure file (<code>DS_ID-[Free/Lab]-AmbientPressureManager.csv</code>).","text":"Column Name Description Technical Note HEADER_TIME_STAMP Time when the ambient pressure was logged Time in <code>YYYY-MM-DD HH:MM:SS</code> format hPa The ambient pressure A float. Unit is milibars MAX_VALUE The maximum possible value that this sensor can provide A float"},{"location":"codebook/#phone-data:-light-sensor","title":"Phone Data: Light Sensor","text":"<p>Android phone's built-in light sensor measured the ambient light. Data are provided in CSV format with the naming convention: <code>DS_ID-[Free/Lab]-LightSensorStats.csv</code>. Table 8 details the columns in this CSV file.</p>"},{"location":"codebook/#table-8.-the-columns-in-the-light-sensor-data-file-(ds_id-[free/lab]-lightsensorstats.csv).","title":"Table 8. The columns in the light sensor data file (<code>DS_ID-[Free/Lab]-LightSensorStats.csv)</code>.","text":"Column name Description Technical note HEADER_TIME_STAMP Time when the light sensor data was logged Time in <code>YYYY-MM-DD HH:MM:SS</code> format LUMINANCE The illuminance recorded A float. Unit is lux MAX_VALUE The maximum possible value that this sensor can provide A float"},{"location":"codebook/#phone-data:-proximity-sensor","title":"Phone Data: Proximity sensor","text":"<p>The Android phones\u2019 proximity sensor measured the approximate distance to an object directly in front of the phone\u2019s face (e.g., the user\u2019s face). Data are provided in CSV format with the naming convention: <code>DS_ID-[Free/Lab]-ProximitySensorManagerService.csv</code>. Table 9 details the columns in this CSV file.</p>"},{"location":"codebook/#table-9.-the-columns-in-the-proximity-data-file-(ds_id-[free/lab]-proximitysensormanagerservice.csv).","title":"Table 9. The columns in the proximity data file (<code>DS_ID-[Free/Lab]-ProximitySensorManagerService.csv)</code>.","text":"Column Name Description Technical Note HEADER_TIME_STAMP Time when the proximity value was logged Time in <code>YYYY-MM-DD HH:MM:SS</code> format PROXIMITY The proximity value A float. Unit is cm MAX_VALUE The maximum possible value that this sensor can provide A float"},{"location":"codebook/#_3","title":"Codebook","text":""},{"location":"codebook/#phone-data:-acceleration","title":"Phone Data: Acceleration","text":"<p>The Android phone\u2019s built-in accelerometer measured triaxial acceleration data. Data are stored in CSV format with the naming conventions: <code>DS_ID-[Free/Lab]-Acceleration.csv</code>. Using the Android API, we set the sampling rate to 50 Hz. Although the Android API tries to keep a constant sampling rate following our settings, the actual sampling rate might not be exactly 50 Hz. Table 12 details the columns in this CSV file.</p>"},{"location":"codebook/#table-12.-the-columns-in-the-acceleration-data-file-(ds_id-[free/lab]-acceleration.csv)-.","title":"Table 12. The columns in the acceleration data file (<code>DS_ID-[Free/Lab]-Acceleration.csv)</code> .","text":"Column Name Description Technical Note HEADER_TIME_STAMP Time when the acceleration was logged Time in <code>YYYY-MM-DD HH:MM:SS</code> format Acceleration X Acceleration in the X axis A float, unit is in g Acceleration Y Acceleration in the Y axis A float, unit is in g Acceleration Z Acceleration in the Z axis A float, unit is in g"},{"location":"codebook/#phone-data:-app-event-counts","title":"Phone Data: App Event Counts","text":"<p>We also collected phone usage data (i.e., if the user turned the phone on or if the user launched an application). Data are provided in CSV format with the naming convention: <code>DS_ID-[Free/Lab]-AppEventCounts.csv</code>. Table 7 details the columns in this CSV file.</p>"},{"location":"codebook/#table-7.-the-columns-in-the-app-event-counts-file-(ds_id-[free/lab]-appeventcounts.csv).","title":"Table 7. The columns in the app event counts file (<code>DS_ID-[Free/Lab]-AppEventCounts.csv)</code>.","text":"Column Name Description Technical Note HEADER_TIME_STAMP Time when the interaction was logged Time in <code>YYYY-MM-DD HH:MM:SS</code> format PACKAGE_NAME The name of the application that participants interacted with A string representing the app name EVENT_TYPE Phone usage and app usage event logs A string representing the event logs. The UsageEvents.Event Android API provides a complete list of possible interaction events. Based on our experiments, some of the more important events are \u201cKEYGUARD_HIDDEN\u201d/ \u201cKEYGUARD_SHOWN\u201d for screen on/off states, and \u201cMOVE_TO_FOREGROUND\u201d/\u201dMOVE_TO_BACKGROUND\u201d when users interact with an application or when an application displays notifications in the foreground"},{"location":"codebook/#phone-data:-notification-logs","title":"Phone Data: Notification Logs","text":"<p>We used the Android API to log the package names of notifications sent to the phone. Notification log data are stored in CSV format with the following naming convention: <code>DS_ID-[Free/Lab]-NotificationCounts.csv</code>. Table 10 details the columns in this CSV file.</p>"},{"location":"codebook/#_4","title":"Codebook","text":""},{"location":"codebook/#_5","title":"Codebook","text":""},{"location":"codebook/#table-10.-the-columns-in-the-notification-log-data-file-(ds_id-[free/lab]-notificationcounts.csv).","title":"Table 10. The columns in the notification log data file (<code>DS_ID-[Free/Lab]-NotificationCounts.csv)</code>.","text":"Column Name Description Technical Note HEADER_TIME_STAMP The time when any application sends a notification to the user. Time in <code>YYYY-MM-DD HH:MM:SS</code> format PACKAGE_NAME The app that created this notification A string"},{"location":"codebook/#phone-data:-step-count","title":"Phone Data: Step count","text":"<p>We used the Android API to track hourly step counts. The step count data are stored in CSV format with the naming convention: <code>DS_ID-[Free/Lab]-StepCounterService.csv</code>. Step counts are recorded every hour. The step counts at each row reflect the total number of steps that participants took since the previous time step count was recorded. The first value reported in the CSV file is the total number of steps taken since the last time the phone was rebooted. Table 11 details the columns in this CSV file.</p>"},{"location":"codebook/#table-11.-the-columns-in-the-step-count-data-file-(ds_id-[free/lab]-stepcounterservice.csv).","title":"Table 11. The columns in the step count data file (<code>DS_ID-[Free/Lab]-StepCounterService.csv)</code>.","text":"Column Name Description Technical Note HEADER_TIME_STAMP Time when the step count was logged. Each time stamp was sampled at a minimum of one hour apart Time in <code>YYYY-MM-DD HH:MM:SS</code> format STEP_THIS_HOUR The total step counts since the last time step counts were reported. The first value in the file is the total number of steps since the phone was rebooted An integer STEP_SINCE_REBOOT Number of step counts since the phone was last rebooted An integer"},{"location":"codebook/#psg-sleep-data-(sleep-protocol-only)","title":"PSG Sleep Data (Sleep Protocol Only)","text":"<p>During up to two nights of at-home sleep during the Sleep protocol, polysomnography (PSG) sleep data were recorded using the Nox A1 PSG system (see The PAAWS Study Data Collection Protocol). We configured the Nox A1 PSG system not to record audio, but the system still recorded \u201cloudness\u201d (in dB) to determine snoring. The raw PSG sleep data was then scored (labeled) by trained researchers specializing in PSG data to determine the sleep/wake times, sleep stages, and other sleep events. </p> <p>PSG data and scored sleep events are stored in the <code>sleep/</code> folder. The PSG data are stored in EDF format with the naming convention: <code>DS_ID-Sleep-Night[1/2].edf</code>. Table 13 details the different available signals in each EDF file (and their usage for sleep scoring). </p>"},{"location":"codebook/#table-13.-available-signals-in-the-psg-data-(ds_id-sleep-night[1/2].edf)-with-their-corresponding-usage-for-sleep-scoring.","title":"Table 13. Available signals in the PSG data (<code>DS_ID-Sleep-Night[1/2].edf)</code> with their corresponding usage for sleep scoring.","text":"Signal Name Source Signal(s) (if derived) Scoring Uses Signal Description ecg N/A Identify ECG arrhythmia Raw ECG data heart rate ECG Primary signal for assessing high/low heart rate and reinforcing ambiguous staging/events, which include HR changes An R-wave detection algorithm is run to detect each heartbeat in the ECG signal. The instantaneous heart rate is the reciprocal of the intervals between successive heartbeats. The heart rate signal has the unit [bpm] (beats per minute) pleth N/A Confirm SpO2 signal strength and reliability. Aid in the identification of respiratory events and arousals when few signals are available/reliable Measure of blood volume changes displayed as pulse oximeter photoplethysmographic (PPG) signal pulse SpO2 An alternate signal for assessing high/low heart rate and reinforcing ambiguous staging/events, which include HR changes Measure of heart rate via pulse oximeter photoplethysmographic (PPG) signal waveform activity Gravity X and Gravity Y Reinforce sleep/wake transitions, especially studies scored sleep/wake only Indication on patient activity/movements. The Activity signal is calculated from raw gravity signals (X and Y axes) measured by a 3-dimensional accelerometer in the Nox recorders. The measured gravity signal is differentiated with respect to time and scaled by the correct scaling factor to create the derived activity signal left leg N/A Identify periodic limb movements Left anterior tibialis EMG activation right leg N/A Identify periodic limb movements Right anterior tibialis EMG activation. abdomen rip N/A Differentiate central vs obstructive events based on effort. Alternate signal for identifying apneas and hypopneas. Estimated changes in lung volume via respiratory inductance plethysmography (RIP) measured at the waist. audio volume db Audio Volume Primary signal for identifying snoring to assess central vs. obstructive events and score \u201csnore trains\u201d of &gt;=4 consecutive snores. An Audio Volume signal in logarithmic scale (with units of decibels) is automatically calculated from the raw Audio Volume signal, which is in linear scale. The transform used to calculate the signal is V_dB \\= 20 log(x/P_0), where V_dB is the volume in decibels, P is the raw audio volume signal (which is a pressure signal with units of Pa) and P_0 is the reference sound pressure, which has a value of P_0 \\= 20 uPa in the Noxturnal US software flow (aka Cannula Flow) Raw (Cannula) Pressure An alternate signal for identifying apneas and hypopneas The Cannula Flow signal is a qualitative signal derived from the raw nasal Cannula Pressure signal and has the unit [cmH2O]. The nasal Cannula Pressure signal is low-pass filtered at 3 Hz and then the cannula flow signal is derived from a non-linear transformation flow limitation Cannula Pressure Used to assist in differentiating between central and obstructive hypopnea when clear paradoxical movement exists on RIP belts The Flow Limitation signal is derived by using a mathematical formula for calculating the flatness of an inhalation nasal pressure Raw Pressure An alternate flow signal for identifying apneas and hypopneas The Nasal (cannula) Pressure signal is calculated on T3 and A1 devices, but in later versions of the devices, the Nasal Pressure signal is calculated in Noxturnal using the Raw Pressure signal, if the Mask Pressure channel is included in the device profile for the recording. The Raw Pressure signal is filtered with a high-pass filter to create the Nasal Pressure signal position Gravity X and Gravity Y Reinforce sleep/wake transitions, especially studies that scored sleep/wake only. Assess supine vs. non-supine sleep Indication of patient posture to discriminate between upright, supine, prone, left, and right positions. The Position signal is created from Gravity X and Gravity Y and is the angle of the rotation of the body. It ranges from -180\u00b0 to 180\u00b0 and is 0\u00b0 if the patient is facing directly upwards rip sum RIP Abdomen and RIP Thorax The primary signal for differentiating central vs obstructive events based on respiratory effort. An alternate signal for identifying apneas and hypopneas The RIP Sum [V] is calculated as the sum of the RIP Abdomen and RIP Thorax signals snore (aka Cannula Snore) Raw (Cannula) Pressure An alternate signal for identifying snoring to assess central vs. obstructive events and score \"snore trains\" of &gt;=4 consecutive snores The snoring signal (Cannula Snore) is derived by high-pass filtering a raw nasal Cannula Pressure or airflow signal spo2 N/A Identifying respiratory events and assessing severity based on O2 desaturation Peripheral Capillary Oxygen Saturation (SpO2) via pulse oximeter spectrophotometry rip flow RIP Abdomen and RIP Thorax Primary signal for identifying apnea and hypopnea and assessing central vs. obstructive hypopneas The belt flow is calculated from a derivative of the sum of the RIP Abdomen and RIP Thorax signals and has the unit [V/s] thorax rip N/A Differentiate central vs obstructive events based on effort. An alternate effort signal for identifying apneas and hypopneas Estimated changes in lung volume via respiratory inductance plethysmography (RIP) measured at the thorax 1-2 1 (chin EMG) and 2 (chin EMG) Sleep Staging (arousals, REM transitions) Derivation of submental EMG activation (Left-Right) 1-F 1 (chin EMG) and F (chin EMG) Sleep Staging (arousals, REM transitions) Derivation of submental EMG activation (Left-Frontal) 2-F 2 (chin EMG) and F (chin EMG) Sleep Staging (arousals, REM transitions) Derivation of submental EMG activation (Right-Frontal) c3-m2 C3 (EEG) and M2 (EEG) Sleep Staging (all stages) Derivation of EEG activity in left central lobe (right mastoid process reference) c4-m1 C4 (EEG) and M1 (EEG) Sleep Staging (all stages) Derivation of EEG activity in right central lobe (left mastoid process reference) e1-m2 E1 (EOG) and M2 (EEG) Sleep Staging (sleep/wake transitions, REM) Derivation of left eye movement (right mastoid process reference) e2-m2 E2 (EOG) and M2 (EEG) Sleep Staging (sleep/wake transitions, REM) Derivation of right eye movement (right mastoid process reference) f3-m2 F3 (EEG) and M2 (EEG) Sleep Staging (all stages) Derivation of EEG activity in the left frontal lobe (right mastoid process reference) f4-m1 F4 (EEG) and M1 (EEG) Sleep Staging (all stages) Derivation of EEG activity in the right frontal lobe (left mastoid process reference) o1-m2 O1 (EEG) and M2 (EEG) Sleep Staging (arousals, sleep/wake transitions) Derivation of EEG activity in the left occipital lobe (right mastoid process reference) o2-m1 O2 (EEG) and M1 (EEG) Sleep Staging (arousals, sleep/wake transitions) Derivation of EEG activity in the right occipital lobe (left mastoid process reference)"},{"location":"codebook/#sleep-data-scoring","title":"Sleep data scoring","text":"<p>The scored sleep data (labels for sleep derived from the PSG data) are stored in the <code>sleep/</code> folder in CSV format with the naming convention: <code>DS_ID-Sleep-Night[1/2]_scored_events.csv</code>. Table\u200c\u00a014 details the different columns provided in the scored events file used to analyze sleep stages and sleep events. Sleep events can be automatically tagged (e.g., different sleeping posture automatically computed by the Noxturnal software), manually tagged (e.g., different sleep stages), or tagged automatically with later manual adjustment (e.g., oxygen desaturation events can be automatically detected but require manual confirmation to ensure the events are not caused by poor connection). All possible sleep events are detailed in Table 15.</p>"},{"location":"codebook/#table-14.-details-of-columns-in-the-scored-sleep-event-file-(ds_id-sleep-night[1/2]_scored_events.csv)-derived-from-the-raw-psg-data.","title":"Table 14. Details of columns in the scored sleep event file (<code>DS_ID-Sleep-Night[1/2]_scored_events.csv) derived from the raw PSG data</code>.","text":"Column Name Description Technical Note Event The different events that occurred during sleep. An event can be automatically scored by the Noxturnal software or manually scored by an expert sleep researcher A string containing the event. Details of all possible events and their meaning are in Table 15 Duration Duration of the event A floating point number, unit is in seconds Start time Start time of an event In <code>YYYY-MM-DD HH:MM:SS</code> format End time End time of an event In <code>YYYY-MM-DD HH:MM:SS</code> format Start epoch The 30-second epoch during which an event tag begins An integer End epoch The 30-second epoch during which an event tag ends An integer"},{"location":"codebook/#table-15.-all-possible-psg-event-types-in-the-psg-sleep-labels-(ds_id-sleep-night[1/2]_scored_events.csv).-an-event-can-either-be-automatically-scored-by-the-noxturnal-psg-software-(auto),-automatically-scored-with-expert-edits-(auto+manual-editing),-or-scored-only-by-an-expert-sleep-researcher-(manual).","title":"Table 15. All possible PSG event types in the PSG sleep labels (DS_ID-Sleep-Night[1/2]_scored_events.csv). An event can either be automatically scored by the Noxturnal PSG software (Auto), automatically scored with expert edits (Auto+manual editing), or scored only by an expert sleep researcher (manual).","text":"Event Tag Event Auto or Manual Scoring Event Definition Left Body Position Left Auto Participant position left, derived from A1's \"gravity\" signals Right Body Position Right Auto Participant position right, derived from A1's \"gravity\" signals Supine Body Position Supine Auto Participant position supine, derived from A1's \"gravity\" signals Prone Body Position Prone Auto Participant position prone, derived from A1's \"gravity\" signals Upright Body Position Upright Auto Participant position upright, derived from A1's \"gravity\" signals Bradycardia Bradycardia Auto A period of Pulse Wave Amplitude signal (derived from oximeter) in which Nox autoscoring detects a BPM of \\&lt;40 for &gt;=20 seconds Tachycardia Tachycardia Auto A period of Pulse Wave Amplitude signal (derived from oximeter) in which Nox autoscoring detects a BPM of &gt;100 for &gt;=20 seconds Warning Device Warning Auto Automated warnings from the A1 device, most commonly \"OximeterProbeNotOnFinger\" Notification Device Notification Auto Automated warnings from the A1 device, most commonly \"DisplayTurnedOn/Off\" and \"Battery Status 20%, 10%\" Single Snore Single Snore Auto + manual editing Abrupt, significant increase in A1 Audio Volume dB signal when compared to baseline dB. Nox automated scoring uses an absolute threshold of 65 dB for 0.2-2 seconds to define single snores Snore Train Snore Train Auto + manual editing Periods containing &gt;=3 consecutive single snores Desat SpO2 desaturation Auto + manual editing A decrease in SpO2 signal &gt;= 3% not associated with signal dropout or poor pleth signal Artifact SpO2 artifact Auto + manual editing Periods of SpO2 showing sharp drops to low or zero values, abnormally low baselines when compared to other periods of the same PSG, or unreliable SpO2 activity concurrent with poor pleth signal Analysis Start Lights Out Manual The beginning of the analysis period used by Noxturnal for generating reports. This is equivalent to \"Lights Out\" in many other PSG systems. Analysis Start is based on either the participant-reported time to bed stated in their sleep notes document or the point in the study when all signals are present and largely clear of artifact indicative of a participant that is hooked up but no longer moving Wake Stage Wake Manual 30-second epoch with &gt;50% containing either or both of: alpha rhythm over the occipital region, and/or other findings consistent with stage wake (e.g., eye blinks, rapid eye movements associated with normal or high chin muscle tone, reading eye movements) N1 Stage N1 Manual 30-second epoch with &gt;50% containing either or both of: alpha rhythm attenuated and replaced with low-amplitude mixed-frequency (LAMF) EEG, and/or other findings consistent with stage N1 (4-7Hz EEG activity slowing by \u22651 Hz when compared to stage W, vertex sharp waves, slow \"rolling\" eye movements) N2 Stage N2 Manual 30-second epoch whose first 15 seconds (or preceding 15 seconds from the previous epoch) contains either or both of; K-complexes unassociated with arousals, sleep spindles.) N3 Stage N3 Manual 30-second epoch with &gt;=20% containing 0.5\u20132 Hz EEG activity with peak-to-peak amplitude &gt;75 \u03bcV, measured over frontal EEG derivations REM Stage REM Manual 30-second epoch containing low-amplitude, mixed-frequency (LAMF) EEG activity without K complexes or sleep spindles, low chin EMG tone for the majority of the epoch, which is concurrent with REMs, REMs at any position within the epoch. Epochs preceding and contiguous with these epochs are also scored as REM when the following are true; EEG shows LAMF EEG without K-complexes or sleep spindles, chin EMG tone is low, there is no intervening arousal, any arousals are not followed by slow eye movements or stage wake Arousal EEG Arousal Manual An abrupt shift in EEG frequency, including alpha, theta, and/or frequencies greater than 16 Hz (but not spindles) lasting &gt;=3 seconds, with at least 10 seconds of stable sleep preceding this change. Scoring arousal during REM requires a concurrent increase in submental EMG lasting &gt;= 1 second. Movement Major Body Movement Manual Abrupt, significant increase in the Activity signal derived from the A1's \"gravity\" signals LM Limb Movement Manual Abrupt, significant increase in either leg EMG signal with duration 0.5-10 seconds. Manual scoring looks for a &gt;=8 \u03bcV amplitude increase above resting EMG baseline, while Nox autoscoring is based on a 5x increase relative to baseline EMG with a maximum amplitude of 300 uV PLM Periodic Limb Movement Manual Scorable limb movement also meets the criteria to be included in PLMS series PLMS Periodic Limb Movement Series Manual A period containing &gt;=4 limb movements with an interval of 5-90 seconds between LMs H. Central Central Hypopnea Manual An amplitude decrease on flow and/or effort signals, which starts or ends in an epoch scored as sleep, has a duration of &gt;=10 seconds, amplitude decrease &gt;=30% when compared to the same signal during stable breathing, is associated with &gt;=3% SpO2 desat or EEG arousal, and contains no evidence of obstructed flow H. Obstructive Obstructive Hypopnea Manual An amplitude decrease on flow and/or effort signal,s which starts or ends in an epoch scored as sleep, has a duration of &gt;=10 seconds, amplitude decrease &gt;=30% when compared to the same signal during stable breathing, is associated with &gt;=3% SpO2 desat or EEG arousal, and contains evidence of obstructed flow A. Central Central Apnea Manual A near 100% amplitude decrease in all flow and effort signals, which starts or ends in an epoch scored as sleep, has a duration of &gt;=10 seconds, and contains no evidence of obstructed flow or RIP breathing effort A. Mixed Mixed Apnea Manual An amplitude decrease on flow and/or effort signals, which starts or ends in an epoch scored as sleep, has a duration of &gt;=10 seconds, contains one period without evidence of breathing effort and flow obstruction, contains a second period with evidence of flow obstruction and/or RIP breathing effort A. Obstructive Obstructive Apnea Manual An amplitude decrease on flow signal,s which starts or ends in an epoch scored as sleep, has a duration of &gt;=10 seconds, amplitude decrease &gt;=90% when compared to the same signal during stable breathing, and contains evidence of RIP breathing effort"},{"location":"codebook/#waking-day-annotations-data","title":"Waking Day Annotations Data","text":"<p>During the FL and SimFL+Lab protocols, participants\u2019 movements were captured on video so we could derive after-the-fact waking day annotations of their activities. During the SimFL+Lab protocol, participants were recorded by a research team member from a third-person viewpoint in addition to wearing the front-facing ego-centric camera they wore throughout the FL protocol. During the FL protocol, participants wore an egocentric front-facing camera on a lanyard around their necks during their waking hours. A trained annotator later viewed the camera footage to annotate the participant\u2019s activities with start/end times at up to a second-by-second precision. More information on our annotation protocols and annotator training can be found in The PAAWS Study Data Collection Protocol.</p> <p>Annotated labels are stored in each participant\u2019s folder in the <code>label/</code> subfolder. The annotation label for each participant is stored in a CSV file with the following naming convention: <code>DS_ID-[Free/Lab]-label.csv</code>. Each row in this file represents a distinct activity (a combination of physical activity type, posture, contextual parameters, and high-level behaviors). Table 16 details each column in this CSV file.</p>"},{"location":"codebook/#table-16.-the-available-columns-in-the-label-file-(ds_id-[free/lab]-label.csv).","title":"Table 16. The available columns in the label file (<code>DS_ID-[Free/Lab]-label.csv</code>).","text":"Column Name Description Technical Note START_TIME Start time of the activity A string in the format <code>YYYY-MM-DD HH:MM:SS.XXX</code> STOP_TIME Stop time of the activity A string in the format <code>YYYY-MM-DD HH:MM:SS.XXX</code> HIGH_LEVEL_BEHAVIOR The overarching high-level activity that might include other lower-level physical activities A string. Labels are non-mutually exclusive, and different labels are separated by the vertical bar character (\u201c CONTEXTUAL_PARAMETERS The contextual parameters that modify a behavior A string. Labels are non-mutually exclusive, and different labels are separated by the vertical bar character (\u201c PA_TYPE The low-level physical activity A string containing a single label POSTURE The posture of the participant A string containing a single label EXPERIMENTAL_SITUATION The condition represents where the current activity took place. An activity can be done as part of the Lab portion of the SimFL+Lab protocol (<code>Lab_Indoors</code>), or as part of either the SimFL or FL protocol (<code>Free_Living</code>). A string containing a single label <p>The annotated labels (as well as all other data that we collected and provided) have been manually synchronized to correct for individual device time drift. Users of the dataset can use the annotation data directly with the acceleration data (or any other data provided).</p>"},{"location":"codebook/#annotation-label-taxonomy","title":"Annotation Label Taxonomy","text":"<p>To label waking day activities in the PAAWS dataset, we created a custom activity taxonomy. The taxonomy is designed to enable labeling of contextualized free-living activity and posture. Each annotation consists of at least two labels: the participant\u2019s posture (one of 13 mutually exclusive options) and physical activity type (one of 49 mutually exclusive options). The taxonomy covers major activities but balances comprehensiveness with the practical constraint that the more complex the taxonomy is, the more difficult the annotation task becomes.  Activities were selected based on common activities in the American Time Use Survey and those found in other datasets. Researchers using our dataset will not be able to view the original front-facing camera video (used for annotation because we must protect participants' privacy). Therefore, to help researchers using the dataset interpret their results, our annotations also include non-mutually exclusive labels about the participant's \u201chigh-level behavior\u201d (HLB) and additional context that may impact the participant's physical activity. The HLB and context labels are meant to provide helpful information when interpreting results detecting activity and posture, but they would need to be used cautiously for model training or evaluation directly because they are non-mutually exclusive and generally have lower inter-rate reliability. </p> <p>Specific details about the annotation taxonomy used in the PAAWS study are described in AnnotationScheme.xlsx. Users of the dataset who have specific questions about the taxonomy or annotator training and practices can leave comments in the annotation taxonomy description AnnotationScheme.xlsx.</p>"},{"location":"codebook/#notes-data","title":"Notes Data","text":"<p>During both the FL and SimFL+Lab protocols, a research assistant took notes regarding general participant behavior and possible deviations from either protocol. Additionally, a research assistant performed daily recall sessions with each participant during the FL protocol and recorded their responses. The <code>notes/</code> folder contains all notes taken during a specific participant's data collection. </p>"},{"location":"codebook/#general-note","title":"General Note","text":"<p>General notes on participants\u2019 behaviors or any equipment issues are provided as a raw text file with the naming convention: <code>DS_ID-[Free/Lab]-GeneralNotes.txt</code>. This note might provide additional context on how participants behaved or whether there are special circumstances (e.g., participant had a prosthetic leg) during the data collection process that data users should consider. </p>"},{"location":"codebook/#protocol-deviations-notes-(simfl+lab-only)","title":"Protocol Deviations Notes (SimFL+Lab Only)","text":"<p>We provide detailed notes on possible deviations from the usual protocol in the SimFL+Lab session. These notes are in CSV format with the naming convention <code>DS_[ID]-Lab-ProtocolDeviations.csv.</code>Each row in the <code>DS_[ID]-Lab-ProtocolDeviations.csv</code> represents an instance where the participant did not follow the instructions in our protocol, or there was a sensor wear deviation (e.g., a sensor was not worn at a given moment).. The column names for the protocol deviation notes are defined in Table 17.</p>"},{"location":"codebook/#table-17.-detailed-description-for-each-column-in-the-computer-readable-note-file-(ds_id-lab-protocoldeviations.csv)-from-simfl+lab-session","title":"Table 17.  Detailed description for each column in the computer-readable note file (DS_ID-Lab-ProtocolDeviations.csv) from SimFL+Lab session","text":"Column name Description Technical note START_TIME The starting time of this note item A string written in the format <code>M/DD/YYYY HH:MM:SS</code> STOP_TIME The stop time of a note item. Some events might not have a stop time if the time is not reported or is not applicable A string written in the format <code>M/DD/YYYY HH:MM:SS</code> NOTE_TYPE The type of this note item. This is useful for quickly filtering out certain events of interest, especially for automated processing All possible note types are: <code>sensor_not_worn,sensor_fell_off, deviation_from_protocol.</code> SENSOR What sensors were affected for this note item Possible sensors to (not) wear are: <code>Accelerometer/IMU</code> (Actigraph GT9X devices), <code>HR_Monitor</code> (heart rate monitor), <code>MET_Cart</code> (the metabolic mask) PROTOCOL_ACTIVITY_AFFECTED What activities were affected A string representing the protocol affected. A detailed list of activities performed in the lab is provided in SimFL+Lab data collection protocol."},{"location":"codebook/#recall-notes-(fl-only)","title":"Recall Notes (FL Only)","text":"<p>We also provide detailed notes from the daily recall sessions during the FL protocol. These notes encompass self-report data included recalled activities, sensor wear issues. These notes are in CSV format with the following naming convention: <code>DS_ID-Free-RecallNotes.csv</code>.</p> <p>Each row in the <code>DS_ID-Free-RecallNotes.csv</code> file represents an item that the participant reported to the researcher during the daily recall sessions. The columns of the recall notes CSV files are defined in Table 18. Table 19 further details possible values in the VALUE column and SENSOR column for each value in the NOTE_TYPE column.</p>"},{"location":"codebook/#table-18.-detailed-description-for-each-column-in-the-computer-readable-recall-note-(ds_id-free-recallnotes.csv)-from-free-living-session","title":"Table 18. Detailed description for each column in the computer-readable recall note (DS_ID-Free-RecallNotes.csv) from free-living session","text":"Column Name Description Technical Note START_TIME The starting time of this note A string written in the format <code>M/D/YYYY HH:MM:SS</code>. In some cases, participants self-reported their activities but did not provide a start time. These events will not have a start time, and this field might be left blank. STOP_TIME The stop time of this note A string written in the format <code>M/D/YYYY HH:MM:SS.</code> In some cases, participants self-reported their activities but did not provide a start time. These events will not have a start time, and this field might be left blank. NOTE_TYPE The note type of this note item. This is useful for quickly filtering out certain events of interest, especially for automated processing All possible note types are: <code>self_report_in_bed, self_report_sleep, sensor_not_worn,sensor_malfunction activity_recall, camera_not_worn_self_report, PSG_report_sleep, camera_not_worn_self_report, sensor_not_worn_self_report, study_length</code>. Each note type (and the associated possible values) are explained in Table 19 SENSOR This field explains what sensor was not worn (either identified by self-report or manual checking).This value is non-null exclusively with the <code>sensor_not_worn</code> and <code>sensor_not_worn_self_report</code> note type The possible values are: <code>Accelerometer</code> (Actigraph GT9X devices) and <code>PSG</code> (Noxturnal A1 PSG system) VALUE For certain values of <code>NOTE_TYPE</code>, we provide a value. Table 19 details the possible combination of values in the <code>NOTE_TYPE</code> and <code>VALUE</code> columns. Values of this column can either be a number between 0-10 (inclusive), or one of the following: <code>water_based_activity, researcher_related, battery_issue, sensor_malfunction, sensor_disruption_other</code>. RECALL_POSTURE For the <code>activity_recall</code> note type, this field represents the self-report posture of the participant during a time when they reported not wearing a camera. This field will be left blank if the self-report recall does not include a posture Any string as defined in our posture annotation taxonomy RECALL_PA_TYPE For the <code>activity_recall</code> note type, this field (if filled in) represents the self-report physical activity of the participant during a time when they reported not wearing a camera. This field will be left blank if the self-report recall does not include a physical activity type Any string as defined in the physical activity annotation taxonomy RECALL_HLB For the activity_recall note type, this field (if filled in) represents the self-report high-level behavior of the participant during a time when they reported not wearing a camera. This field will be left blank if the self-report recall does not include a high-level behavior Any string or combination of strings from the high-level behavior annotation scheme. Multiple values are separated using \u201c RECALL_CP For the a<code>ctivity_recall</code> note type, this field (if filled in) represents the self-report contextual parameters of the participant during a time when they reported not wearing a camera. This field will be left blank if the self-report recall does not include a contextual parameter Any string or combination of strings from the contextual parameter annotation scheme. Multiple values are separated using \u201c NOTE Provides additional context on the note General comments from a research assistant clarifying unusual situations"},{"location":"codebook/#table-19.-details-of-possible-values-in-the-value-column-and-sensor-column-for-each-value-in-the-note_type-column-used-in-the-computer-readable-recall-notes-file-(ds_id-free-recallnotes.csv)-from-free-living-data-collection-protocol.","title":"Table 19. Details of possible values in the VALUE column and SENSOR column for each value in the NOTE_TYPE column used in the computer-readable recall notes file (DS_ID-Free-RecallNotes.csv) from free-living data collection protocol.","text":"NOTE_TYPE Description SENSOR VALUE self_report_in_bed Timeframe participant reported being in bed N/A N/A self_report_sleep Timeframe participant reported being asleep N/A A number between 0-10 (inclusive) representing the self-report sleep quality of that night using a \u201creverse scale,\u201d where 0 represents the best possible sleep quality, and 10 represents the worst possible sleep quality sensor_not_worn Time that a trained researcher determined that a sensor was not worn using Signaligner The only possible value is <code>Accelerometer</code> (Actigraph GT9X devices) N/A sensor_malfunction Time that a trained researcher determined that a sensor malfunctioned and collected incorrect data (see The PAAWS Study Data Collection Protocol for details on how this was determined) This field represents the sensor type that was affected by this issue.  Possible sensors with non-wear during the FL protocol are  <code>Accelerometer</code> (Actigraph GT9X devices) and <code>PSG</code> (for sleep) N/A activity_recall Participant\u2019s reported activity during a time where footage is not available. The activity is described using the annotation scheme and is provided in the RECALL_POS, RECALL_PA, RECALL_HLB, RECALL_CP for posture, physical activity, high level behavior, and contextual parameters respectively N/A N/A PSG_report_sleep Time the participant fell asleep, obtained from scoring PSG data N/A N/A camera_not_worn_self_report Participant\u2019s reported camera not worn time. This usually occurs just before the participant was going to bed and just after getting out of bed N/A N/A sensor_not_worn_self_report Participant\u2019s reported sensor non-wear time This field represents what sensor was not worn. Possible sensors with nonwear are <code>Accelerometer</code> (Actigraph GT9X devices) and <code>PSG</code> (for sleep) Reasons given for why the sensor was not worn. Possible values are: <code>battery_issue</code> (devices have battery issues; usually low batteries), <code>water_based_activity</code> (taken off when showering or swimming), <code>sensor_malfunction</code> (sensor is broken), <code>researcher_related</code> (a researcher needed that sensor taken off for study purposes; usually for SimFL+Lab session), <code>sensor_disruption_other</code> (some other issues that will be explained in the Additional_Note section) study_length The duration of FL protocol. Data collected outside this interval of time should be ignored. This note denotes the timeframe the participant wore all sensors for the FL study N/A N/A"},{"location":"protocol/","title":"PAAWS Data Collection and Preparation Procedures","text":"<p>This codebook details the data collection protocols (i.e., what participants did during the PAAWS study) for the PAAWS study. For reference on the specific measurements collected and how to parse/use the data collected from the PAAWS Study, refer to The PAAWS Dataset Codebook.docx.</p> <p>The PAAWS Study data were collected across three protocols: the simulated free living and lab (SimFL+Lab) protocol, the free-living (FL) protocol, and the Sleep protocol (completed during the FL protocol). Data from the all sensors were synchronized to each other and the annotations. Research assistants conducted quality control throughout, with a researcher verifying the process and signing off on the work..  </p>"},{"location":"protocol/#simfl+lab-data-collection-protocol","title":"SimFL+Lab Data Collection Protocol","text":"<p>The SimFL+Lab Protocol was an approximately four-hour supervised protocol consisting of an approximately one-hour (minimally controlled) simulated free-living protocol as well as an approximately three-hour (highly controlled) exercise laboratory protocol. </p>"},{"location":"protocol/#simfl+lab-sensors","title":"SimFL+Lab Sensors","text":"<p>For the collection of accelerometer and IMU data during the SimFL+Lab session, we used 21  ActiGraph GT9X Link sensors. The devices were set to sample accelerometer data at a rate of 80 Hz and to sample IMU data at a rate of 100 Hz. Additionally, participants wore a Polar H10 heart rate monitor on their chests throughout the protocol. </p> <p>During a portion of the protocol, participants wore a mask connected to a CPET Quark RMR Cosmed indirect calorimeter. This device collected breath-by-breath oxygen and carbon dioxide input and output to estimate the metabolic equivalent of task (MET) during predetermined activities.</p> <p>In addition to the worn sensors, participants carried their personal mobile phones (with a GT9X Link taped to the back) throughout the SimFL+Lab session. If their personal phone was a compatible Android phone, custom data collection software was run on the phone to collect additional data. </p>"},{"location":"protocol/#preparation","title":"Preparation","text":"<p>During the hour before each participant arrived, researchers prepared for the data collection protocol by:</p> <ul> <li>Calibrating the indirect calorimeter (including calibrating flowmeters and metabolic reference values) using the on-board software.   </li> <li>Preparing straps to secure the ActiGraph GT9X sensors to the participant.  </li> <li>Preparing the Polar H10 heart rate monitor and strap.  </li> <li>Initializing ActiGraph GT9X Link sensors.   </li> <li>Creating sensor synchronization points by placing all the sensors into a box, shaking the box, and dropping the box onto a flat surface. The box was then left at rest until the participant arrived so it was easy to identify the shaking motion for synchronizing sensor data. The synchronization points were used to ensure data could be time-synced to sub-second precision across all sensors.</li> </ul>"},{"location":"protocol/#sensor-wear-locations","title":"Sensor Wear Locations","text":"<p>We collected data from 21 GT9X Link sensors in the SimFL+Lab sessions. Twenty of these sensors were worn on a participant\u2019s body and one was attached to the back of a participant\u2019s phone. Sensors were secured to the participant\u2019s body using fitting straps, clips, and tape. Table 1 describes all 21 sensor locations and Figure 1 shows the sensor wear locations.</p>"},{"location":"protocol/#figure-1.-images-of-sensors-on-a-person\u2019s-body-(from-left-to-right-and-top-to-bottom):-(a)-right-and-left-wrists-top-sensors,-(b)-right-and-left-wrists-bottom-sensors,-(c)-right-waist-sensors,-(d)-left-waist-sensors,-(e)-right-and-left-thigh-sensors,-(f)-right-ankle-anterior-sensor,-(g)-right-ankle-lateral-sensor,-(h)-right-ankle-medial-sensor,-and-(i)-right-ankle-posterior-sensor.","title":"Figure 1. Images of sensors on a person\u2019s body (from left to right and top to bottom): (a) Right and left wrists top sensors, (b) right and left wrists bottom sensors, (c) right waist sensors, (d) left waist sensors, (e) right and left thigh sensors, (f) right ankle anterior sensor, (g) right ankle lateral sensor, (h) right ankle medial sensor, and (i) right ankle posterior sensor.","text":""},{"location":"protocol/#table-1.-the-21-sensor-locations-used-in-the-paaws-simfl+lab-protocol.","title":"Table 1. The 21 sensor locations used in the PAAWS SimFL+Lab protocol.","text":"Location name Researchers (helped participants) put the sensor on the \u2026 Right Wrist Top Dorsal aspect of right wrist on or proximal to the head of the ulna, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side (thumb side) of the wrist when the hand is pronated, using the ActiGraph Link Watch Strap. Right Wrist Bottom Ventral aspect of the right wrist positioned immediately proximal to the device worn dorsally, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side of the wrist when the hand is supinated, using the ActiGraph Link Watch Strap. Left Wrist Top Dorsal aspect of left wrist positioned on or proximal to the head of the ulna, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side (thumb side) of the wrist when the hand is pronated, using the ActiGraph Link Watch Strap. Left Wrist Bottom Ventral aspect of the left wrist positioned immediately proximal to the device worn dorsally, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side of the wrist when the hand is supinated, using the ActiGraph Link Watch Strap. Right Waist Anterior Right hip on the anterior axillary line (coronal line on the anterior torso marked by the anterior axillary fold) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the medial side of the body). Right Waist Mid Right hip on the mid axillary line (coronal line on the torso between the anterior and posterior axillary lines) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the anterior side of the body). Right Waist Posterior Right hip on the posterior line (coronal line on the posterior torso marked by the posterior axillary fold) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the anterior side of the body). Left Waist Anterior Left hip on the anterior axillary line (coronal line on the anterior torso marked by the anterior axillary fold) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the medial side of the body). Left Waist Mid Left hip on the mid axillary line (coronal line on the torso between the anterior and posterior axillary lines) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the anterior side of the body). Left Waist Posterior Left hip on the posterior line (coronal line on the posterior torso marked by the posterior axillary fold) below the iliac crest, positioned on the belt or pant using the ActiGraph Link Belt Clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is upright (reads towards the anterior side of the body). Right Thigh Anterior side of the right thigh midway between inguinal crease and the patella of the knee. The device is adhered to the skin using a hypoallergenic medical tape (3M Tegaderm). The ActiGraph should be worn to ensure the flat end of the device is on the side of the patella. Ensure the ActiGraph is positioned upright with the \u201cActiGraph\u201d inscription reading upright from the medial to lateral sides of the thigh. Left Thigh Anterior side of the left thigh midway between inguinal crease and the patella of the knee. The device is adhered to the skin using a hypoallergenic medical tape (3M Tegaderm). The ActiGraph should be worn to ensure the flat end of the device is on the side of the patella. Ensure the ActiGraph is positioned upright with the \u201cActiGraph\u201d inscription reading upright from the medial to lateral sides of the thigh. Right Ankle Anterior Anterior aspects of the right ankle, positioned such that the ActiGraph insignia on the front of the device reads from the lateral to medial direction and the device is oriented upright. Right Ankle Lateral Lateral aspects of the right ankle, positioned just proximally to the lateral malleolus using a compression sock and medical tape, such that the ActiGraph insignia on the front of the device reads from the posterior to anterior direction and the device is oriented upright. Right Ankle Medial Medial aspects of the right ankle, positioned such that the ActiGraph insignia on the front of the device reads from the anterior to posterior direction and the device is oriented upright. Right Ankle Posterior Posterior aspects of the right ankle, positioned such that the ActiGraph insignia on the front of the device reads from the medial to lateral direction and the device is oriented upright. Left Ankle Anterior Anterior aspects of the left ankle, positioned such that the ActiGraph insignia on the front of the device reads from the lateral to medial direction and the device is oriented upright. Left Ankle Lateral Lateral aspects of the left ankle, positioned just proximally to the lateral malleolus using a compression sock and medical tape, such that the ActiGraph insignia on the front of the device reads from the posterior to anterior direction and the device is oriented upright. Left Ankle Medial Medial aspects of the left ankle, positioned such that the ActiGraph insignia on the front of the device reads from the anterior to posterior direction and the device is oriented upright. Left Ankle Posterior Posterior aspects of the left ankle, positioned such that the ActiGraph insignia on the front of the device reads from the medial to lateral direction and the device is oriented upright. Phone Back of the phone, positioned such that the ActiGraph insignia on the front of the device reads upright from the top to the bottom of the phone. The sensor was attached to a custom plastic clip glued to the phone\u2019s case."},{"location":"protocol/#simfl+lab-data-collection-session","title":"SimFL+Lab Data Collection Session","text":"<p>Participants were instructed to wear comfortable clothes that they could move around in (e.g., athletic clothing) and comfortable footwear for walking/running (e.g., sneakers) for the SimFL+Lab data collection. </p> <p>When a participant arrived, a researcher obtained informed consent and further explained the SimFL+Lab protocol. The researcher put nineteen of the GT9X Link sensors on the participant and instructed the participant how to place the remaining two thigh sensors. Additionally, participants were instructed on how to put on the Polar heart rate monitor. The thigh sensors and heart rate monitors were put on in a private location, outside of the sight of the researcher because they had to be worn under clothing. </p> <p>Researchers photographed the sensor-wear locations and orientations for all visible sensors to permit verification of any sensor placement, orientation, or sensor functionality issues after data collection had concluded. When participants put on the thigh sensors, they were instructed to photograph the thigh sensors with their knees visible. Any known sensor placement or orientation issues discovered were documented in the participant notes. </p> <p>Depending on the current weather and time of day, the researcher decided whether to perform the Simulated Free Living protocol or the Controlled lab protocol first. Both protocols were always completed, but the order in which they were completed might be changed. In 116 of 252 (46% of) data collections, the SimFL protocol was completed before the Lab protocol. </p> <p>During the entire portion of the SimFL+Lab data collection protocol, a researcher filmed the participant with a C3 Cammpro camera, resulting in third-person video of the participant\u2019s lab session. This third-person perspective video was used to precisely label activities performed during the SimFL+Lab protocol. Participants also wore a front-facing camera around their neck to record their simulated free-living and lab sessions from a first-person view; this was the same camera worn in the Free-Living protocol with the same perspective. The first-person, front-facing camera footage was used as a backup for annotation, in the event the third-person recording was corrupted or missing due to a technical problem with the camera. In real time, while the participant completed each activity, a research assistant also recorded the current activity on a tablet running custom annotation software during the simulated free-living and laboratory protocol. To accompany each SimFL+Lab protocol, we released the annotations derived from the footage because they are more accurate, not the real-time labels. </p> <p>Once wearing all sensors, participants performed sensor synchronization movements. They began by standing completely still until the research assistant signaled them to walk along a corridor using what we called a \"modified Frankenstein walk\": kicking one leg straight up with each step while keeping both legs rigid, but striking the raised thigh with the opposite hand rather than keeping arms extended. Participants repeated this sequence (standing still, then performing the modified walk) three times. These movements provide reference points to verify proper synchronization between annotations and sensor data.</p>"},{"location":"protocol/#simulated-free-living-(simfl)-protocol","title":"Simulated Free Living (SimFL) Protocol","text":"<p>In the SimFL portion, participants performed 16 scenarios (Table 2). Researchers provided little-to-no guidance or constraints on how the participants performed these scenarios. The only constraint imposed was the ordering of the tasks and the approximate duration of these tasks. While most SimFL sessions followed the ordering of the tasks shown here, there was some variations to accommodate external factors (e.g., weather, road blockage).</p>"},{"location":"protocol/#table-2-description-of-scenarios-completed-by-participants-in-the-paaws-simfllab-protocol","title":"Table 2. Description of scenarios completed by participants in the PAAWS SimFL+Lab protocol.","text":"Scenario Name Description (\u201cThe participant\u2026\u201d) Walking Downstairs with Groceries Walked down five flights of stairs carrying two light grocery bags that were about 5 lbs (2.3 kg) each. Walking to the Train Station Walked from the exercise laboratory building to a nearby train station. Waiting for the Train Waited for the next inbound train. Riding the Train One Stop Rode the train for one stop. There were no restrictions placed on how the participant rode the train. Walk on Phone Call Walked while holding their phone next to their ear and engaging in conversation with the research assistant. Wait in Line at a Coffee Shop Stood in line at a coffee shop and engaged in a conversation with a research assistant. Sit on Bench (Naturally) Sat on a public bench. This activity was conducted outdoors if the weather permitted. Sit on Bench (Conversation) Sat on a public bench and engaged in conversation with the research assistant. This activity was conducted outdoors if the weather permitted. Sit on Bench (Reading) Sat on a public bench and read a provided book. This activity was conducted outdoors if the weather permitted. Sit on Bench (Using Phone) Sat on a public bench and use their phones (e.g., texting). This activity was conducted outdoors if the weather permitted. Grocery Shopping Walked through a grocery store and picked up five items of their choosing. Once five items were selected, the participant returned the items to their correct places in the store. Playing Frisbee Played frisbee with the research assistant. Walking Upstairs with Groceries Walked up five flights of stairs carrying two light grocery bags that were about 5 lbs (2.3 kg) each. Each participant climbed the stairs at their own pace and rested as needed. Biking (Outdoors) Rode a bike for three loops on pavement around a large grassy common, for a total of about 0.26 mile (0.43 km). Elevator Up Rode the elevator up five floors. Elevator Down Rode the elevator down five floors."},{"location":"protocol/#lab-protocol","title":"Lab Protocol","text":"<p>During the controlled lab protocol, participants completed 32 activities within an exercise laboratory at Northeastern University. Participants were given specific instructions on how to complete each activity. They were reminded to adhere to the protocol if they were observed deviating from the protocol. </p> <p>During the Lab protocol, participants were afforded breaks between activities, as needed. We further monitored the heart rate of participants aged 65+ years on the treadmill tasks to ensure their heart rate did not exceed 75% of their estimated maximum heart rate capacity. If their heart rate exceeded this value, we stopped these activities for participant safety and documented what happened in the participant\u2019s data collection notes. All participants could request breaks or opt-out of activities for any reason. Any deviation or \u201cskipped\u201d activities were documented in each participant\u2019s notes.</p> <p>For 13 of the 32 activities in the Lab protocol, participants wore a mask connected to the CPET Quark RMR Cosmed indirect calorimeter.  Most often, these 13 activities were performed at the start of the Lab Protocol and one after the other (i.e., in one block). Before starting these activities, and during each activity,  the research assistants ensured that participants were wearing the mask correctly. Details of activities being performed with the calorimeter are included in Table 3.</p>"},{"location":"protocol/#table-3.-list-of-physical-activity-(pa)-types-performed-while-the-participant-was-wearing-an-indirect-calorimeter-mask.","title":"Table 3. List of Physical Activity (PA) types performed while the participant was wearing an indirect calorimeter mask.","text":"PA_Type Label Instruction (Each participant was instructed to\u2026) Lying_On_Back_Lab Lie on a bed on the back as still as possible. Sitting_Still Sit on a chair, as still as possible, with both arms on the armrests and feet flat on the floor. Sitting_Typing_Lab Type on the provided laptop without stopping. Standing_Still Stand as still as possible with both feet planted on the ground. Folding_Laundry Stand and fold provided laundry (e.g., towels, bed sheets, and some clothing items). If a participant folded all the laundry before the protocol finished, they were instructed to unfold the laundry and repeat the activity. Stationary_Biking_300_Lab Bike on a stationary bike while keeping cadence at 50 rpm following a metronome. The bike resistance was set to 1 kp; the power of the expected biking is 300 kp/min (kilopond per minute). Treadmill_2mph_Lab Walk on a treadmill at 2 mph (3.2 km/h) without holding the treadmill handrails. Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Treadmill_3mph_Hands_Pockets_Lab Walk on a treadmill at 3 mph (4.8 km/h) with hands in pockets. Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Treadmill_3mph_Drink Walk on a treadmill at 3 mph (4.8 km/h) while holding a bottle of water like it was a cup of coffee using their dominant hand. Some participants held the bottle of water in their non-dominant hand and these deviations are documented in their respective notes files. Treadmill_3mph_Briefcase_Lab Walk on a treadmill at 3 mph (4.8 km/h) while carrying a heavy briefcase measured at \\~3.1 kg using their dominant hand. Some participants held the briefcase in their non-dominant hand and these deviations are documented in their respective notes files. Treadmill_3mph_Free_Walk_Lab Walk on a treadmill at 3 mph (4.8 km/h) without holding onto the treadmill handrails. Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Treadmill_4mph_Lab Walk (briskly) on a treadmill at 4 mph (6.4 km/h) without holding onto the treadmill handrails. Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Treadmill_5.5_mph_Lab Run/jog on a treadmill at 5.5 mph (8.9 km/h) without holding onto the treadmill handrails. Participants over 40 years old were not asked to perform this activity. <p>The remaining 19 of the 32 Lab protocol activities were completed without wearing the indirect calorimeter (Table 4).</p>"},{"location":"protocol/#table-4.-list-of-physical-activity-(pa)-types-each-participant-was-asked-to-perform-without-wearing-the-indirect-calorimeter.","title":"Table 4. List of Physical Activity (PA) Types each participant was asked to perform without wearing the indirect calorimeter.","text":"PA_Type Label Instruction (Each participant was instructed to\u2026) Treadmill_3mph_Conversation_Lab Talk with the research assistant while walking on a treadmill at 3\u202fmph (4.8\u202fkmh).  Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Treadmill_3mph_Phone_Lab Walk on a treadmill at 3\u202fmph (4.8\u202fkmh) while holding a phone next to the ear and engaging in conversation with the research assistant.  Some participants held the handrail for their own safety, and these deviations are documented in their respective notes files. Stand_Shelf_Load_Lab Unload a shelf full of binders. Stand_Shelf_Unload_Lab Restock a shelf full of binders. Organizing_Shelf/Cabinet Place bottles from a lower shelf cabinet onto a counter, then move them from the counter into an upper shelf cabinet. The same protocol was repeated in reverse to return the bottles to the lower shelf cabinet. Participants moved the bottles to the counter and back only once. Sweeping Sweep paper flakes on the floor into a dustpan using the provided broom. Vacuuming Vacuum the laboratory hallway using the provided vacuum. Chopping_Food_Lab Chop pieces of play-doh into small chunks using the provided steak knife. Washing_Dishes_Lab Wash a steak knife and plastic plate with the provided sponge and dish soap. Lying_On_Left_Side_Lab Lie on a bed on the left side as still as possible. Lying_On_Stomach_Lab Lie on a bed on the stomach as still as possible. Lying_On_Right_Side_Lab Lie on a bed on the right side as still as possible. Sit_Recline_Talk_Lab Sit down and recline in a chair and engage in a conversation with the researcher. Sit_Recline_Web_Browse_Lab Recline in a chair and use the phone to browse the web. Sit_Writing_Lab Sit upright and write on a piece of paper attached to a clipboard. Stand_Conversation_Lab Stand and talk to the researchers for two minutes. Arm_Curls_Lab Stand and perform two bicep curls for two sets of eight repetitions using two 5 lbs (2.3 kg) dumbbells. Push_Up_Lab and Push_Up_Modified_Lab Perform two sets of eight push-ups. When participants could not do the usual version, they instead performed a modified push-up on their knees. Ab_Crunches_Lab Do two sets of eight abdominal crunches. Machine_Chest_Press_Lab Do two sets of eight presses on a chest press machine at the lowest possible weight (0 added resistance). Machine_Leg_Press_Lab Do two sets of eight presses on a leg press machine at the lowest possible weight (0 added resistance)."},{"location":"protocol/#end-of-the-simfl+lab-session","title":"End of the SimFL+Lab Session","text":"<p>After the SimFL+Lab protocol, researchers removed all the sensors from the participant. The participant removed the thigh sensors and heart rate monitors themselves while out of sight of the researchers.</p> <p>Then, we immediately performed a sensor synchronization. Like the synchronization at the start of the session, this was accomplished by placing all the sensors into a box, shaking the box, and dropping the box onto a flat surface. </p> <p>In most cases, after completing the SimFL+Lab protocol, the participant immediately began the FL protocol. In other cases, the SimFL+Lab protocol occurred in the middle of the FL protocol, in which case the participant removed the FL sensors before the protocol, put on the SimFL+Lab sensors for the SimFL+Lab session, and then put the FL sensors back on before leaving the laboratory.  </p> <p>Once the participant left the laboratory, the researcher thoroughly cleaned all equipment and downloaded data from the devices. Researchers also recorded notes on any deviations from the protocol that may have occurred during either the Lab or the SimFL protocols and on any problems encountered when downloading data off the devices.   A research assistant then performed a manual quality check on all sensors immediately after data collection concluded. To perform this check, the accelerometer signals of all 21 accelerometers were loaded into Signaligner Pro with the labels that a research assistant recorded in real time using the tablet computer. For each activity, a trained research assistant carefully viewed the accelerometer data. Given that there are multiple sensors on the same limb, the research assistant was typically able to identify when a sensor yielded an unexpected acceleration signal. Problems like incorrect sensor orientation or a faulty sensor were identified and rectified or documented in each participant\u2019s notes file.</p>"},{"location":"protocol/#free-living-data-collection-protocol","title":"Free-Living Data Collection Protocol","text":"<p>The PAAWS free-living (FL) protocol portion of the PAAWS study was an approximately eight-day free-living period collecting over seven full days of continuous data. Data collection began partway through Day 1, often just after the SimFL+Lab protocol. It then continued for six full days and seven nights (Day 2 through Day 7). The protocol concluded partway through Day 8.</p> <p>During the FL protocol, participants were asked to engage in their daily life\u2014as they would naturally\u2014while continuously wearing five accelerometers on multiple limbs and an additional sixth accelerometer on the back of their phone. During as much of their waking day as possible, participants also wore a chest-mounted, front-facing camera, the footage of which we used to establish ground-truth labels for each day.</p>"},{"location":"protocol/#free-living-protocol-sensors","title":"Free-Living Protocol Sensors","text":"<p>For the collection of accelerometer data during the FreeLiving session, we used ActiGraph GT9X Link sensors (the same sensors used during the SimFL+Lab protocol). We programmed the devices to sample accelerometer data at a rate of 80 Hz. Unlike in the Lab+SimFL, the device IMU sensors were turned off, which was necessary to achieve one-week of continuous data collection on a single charge. </p> <p>During waking day hours, participants also wore a C3 Cammpro camera on their chest. The camera was set to record front-facing 480p videos at 30 fps. The camera was housed in a custom-made housing that held both the camera and an extended battery. The camera, in its housing, was worn on a lanyard around the neck, with a magnet that helped stabilize the camera by allowing it to stick to the front of a shirt (Figure 2). The camera dimensions were X x X x X cm and it weighed 180 g. </p>"},{"location":"protocol/#figure-2.-left:-the-camera-with-the-custom-made-housing,-extended-battery,-and-lanyard.-right:-an-example-of-how-the-camera-is-worn-on-the-neck,-with-the-magnet-shown-in-front-of-the-shirt-for-illustration-purposes.","title":"Figure 2. Left: The camera with the custom-made housing, extended battery, and lanyard. Right: An example of how the camera is worn on the neck, with the magnet shown in front of the shirt for illustration purposes.","text":"<p>For the duration of the FL protocol, participants were given a laptop that they were instructed to connect to their home internet. The laptop was to be left in the home. Each night, before going to sleep, the participant plugged the camera into the laptop to reset the camera\u2019s internal clock, charge the camera battery, and securely transfer video from that day to the research team overnight. The participant also charged the camera\u2019s extended battery through the laptop overnight. </p>"},{"location":"protocol/#free-living-session-preparation","title":"Free-Living Session Preparation","text":"<p>We initialized six ActiGraph GT9X Link sensors one hour prior to the scheduled participant arrival time. During this one-hour time frame, researchers prepared for the data collection protocol by:</p> <ul> <li>Preparing straps for the ActiGraph GT9X Link sensors.  </li> <li>Creating sensor synchronization points to ensure data could be time-synced to sub-second precision across all sensors. This was accomplished by placing all the sensors into a box, shaking the box, and dropping the box onto a flat surface. The box was then left at rest until the participant arrived so it was easy to identify the shaking motion for synchronizing sensor data. The synchronization points were used to ensure data could be time-synced to sub-second precision across all sensors.  </li> <li>Confirming the camera and extended battery were fully charged,the camera datetime was correct, and the camera was ready to begin recording. </li> </ul>"},{"location":"protocol/#fl-sensor-wear-locations","title":"FL Sensor Wear Locations","text":"<p>In the FL protocol, we collected data from six sensors: five on-body sensors and one on-phone sensor. The details of the wear locations are in Table 5 and Figure 3 shows the on-body sensor wear location.</p>"},{"location":"protocol/#_1","title":"Data Collection Protocol","text":""},{"location":"protocol/#figure-3.-images-of-sensors-on-a-person\u2019s-body-(from-left-to-right):-(a)-right-and-left-wrists-sensors,-(b)-right-waist-sensor,-(c)-right-thigh-sensor,-and-(d)-right-ankle-sensor.","title":"Figure 3. Images of sensors on a person\u2019s body (from left to right): (a) Right and left wrists sensors, (b) right waist sensor, (c) right thigh sensor, and (d) right ankle sensor.","text":""},{"location":"protocol/#table-5.-the-six-sensor-locations-used-in-the-paaws-fl-protocol.","title":"Table 5. The six sensor locations used in the PAAWS FL protocol.","text":"Location name Researchers (helped participants) put sensor on Right Wrist Dorsal aspect of right wrist on or proximal to the head of the ulna, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side (thumb side) of the wrist when the hand is pronated, using the ActiGraph Link Watch Strap. Left Wrist Dorsal aspect of left wrist positioned on or proximal to the head of the ulna, ensuring the sensor\u2019s \u201cActiGraph\u201d inscription is positioned upright on the medial side (thumb side) of the wrist when the hand is pronated, using the ActiGraph Link Watch Strap. Right Waist Right hip on the anterior axillary line (coronal line on the anterior torso marked by the anterior axillary fold) below the iliac crest, positioned around the waist using an elastic band with clip, ensuring the device is oriented so the \u201cActiGraph\u201d inscription is  read towards the anterior side of the body. Note that this sensor was rotated 90 degrees from the position used in the Lab+SimFL protocol. Right Thigh Anterior side of the right thigh midway between inguinal crease and the patella of the knee. The device is adhered to the skin using a hypoallergenic medical tape (3M Tegaderm). The ActiGraph should be worn to ensure the flat end of the device is on the side of the patella. Ensure the ActiGraph is positioned upright with the \u201cActiGraph\u201d inscription reading upright from the medial to lateral sides of the thigh. Right Ankle Lateral aspects of the right ankle positioned just proximally to the lateral malleolus using an elastic band with clip, such that the ActiGraph insignia on the front of the device reads from the posterior to anterior direction. Note that this sensor was rotated 90 degrees from the position used in the Lab+SimFL protocol. Phone Back of the phone, positioned such that the ActiGraph insignia on the front of the device reads upright from the top to the bottom of the phone. The sensor was attached to a custom plastic clip glued to the phone\u2019s case. <p>NOTE: For any users of the PAAWS data using both the FL and SimFL+Lab data, the waist and ankle sensors had to be rotated 90 degrees in the FL protocol as compared with the SimFL+Lab protocol. For these sensors, we had to use sensor straps and holders for more robust and secure limb attachment in free-living, which caused a different sensor orientation.</p>"},{"location":"protocol/#start-of-the-free-living-protocol","title":"Start of the Free-Living Protocol","text":"<p>When the participant arrived at the laboratory, a researcher explained the Free-Living Protocol to the participant and, if necessary, obtained informed consent. The researcher then showed the participant how to put on the ActiGraph sensors and let the participant practice putting the sensors on themselves. After practicing putting on the FL sensors, we gave participants a pamphlet detailing how to properly wear the sensors should they need to take them off throughout the week. Participants were instructed to wear the right thigh sensor, which was secured using a waterproof tape, continuously for the entire week. They were also instructed to wear the four remaining on-body sensors continuously except when engaged in water-based activities, such as showering or swimming. If participants felt any discomfort while wearing the on-body sensors, they were instructed to temporarily remove these sensors. They were instructed to leave the phone sensor attached to their phone\u2019s case and use their phone normally.  </p> <p>If the tape adhering the thigh sensor started to fail, participants were instructed to remove the tape and replace it with new tape (that we provided), as they were shown in the lab. To facilitate comfort, the thigh sensor was attached by: placing a layer of Tegaderm on the thigh; placing the sensor in the desired orientation, on top of the first layer of Tegader; and sealing the sensor in place using a second layer of Tegadermon top. This application created a waterproof seal for the sensor and provided maximal comfort for the participant. </p> <p>Before they began their FL protocol, we also instructed participants on how to wear the front-facing camera around their neck to record their activities from a first-person view during their entire waking day. Participants were asked to start wearing the camera after getting out of bed and keep the camera on for as long as possible during the day. They were instructed to cover up the camera when necessary to protect their privacy. Participants were instructed not to remove the camera unless necessary (e.g., entering locations where filming is not permitted, such as a government building). We also showed participants how to plug the camera into the provided laptop in the evening and how to charge the camera and the auxiliary battery in the camera case (and how researchers could help them do this in the evening, over the phone). Participants were informed they could ask us to delete any footage immediately when the researcher team received it before any review, for any reason. </p> <p>Once participants wore all the sensors and wore the camera and the camera had started recording, we instructed participants to complete five hand claps followed by five knee pulls to create a reference point to verify synchronization between annotations and sensor data.</p> <p>Participants left the laboratory wearing all the sensors and the camera and with the sensor-wear instructions, the laptop, and an extra Tegaderm adhesive. </p>"},{"location":"protocol/#during-the-freeliving-protocol","title":"During the FreeLiving Protocol","text":"<p>During data collection, participants performed two sensor synchronization movements twice daily. At the start and end of each day after putting  the camera on when they got out of bed, participants were instructed to: complete five hand claps followed by five knee pulls in the view of the camera. These movements provide reference points to verify proper synchronization between annotations and the sensor data. At the end of each day, before taking off the camera, the participants were instructed to repeat the synchronization movements above. </p> <p>Each night after the synchronization movements, participants connected the camera to the laptop to upload footage to the server overnight and they plugged in the camera and battery to charge.</p> <p>Each morning, research assistants reviewed the received footage to identify major camera non-wear periods (anything longer than 30 min) or segments where physical activities were unclear (e.g., partially obstructed by clothing or poor lighting conditions). Each of these instances of camera non-wear were noted down. Each morning, a research assistant scheduled a video call with the participant. During this video call session, the research assistant asked questions about the activities the participant performed without the camera and collected self-report sleep data, including time-in-bed and sleep duration.</p>"},{"location":"protocol/#end-of-the-free-living-protocol","title":"End of the Free-Living Protocol","text":"<p>On the final day of the Free-Living Protocol, participants returned to the lab to return the equipment. At the lab, participants performed a final round of synchronization movements by completing five hand claps then five knee pulls in the view of the camera. A research assistant then helped the participant remove all sensors.</p> <p>After the participant left, the research assistant performed a final synchronization step by placing all the GT9X Link sensors into a box, shaking the box, and dropping the box onto a flat surface.</p> <p>The researcher thoroughly cleaned all equipment and downloaded data off the devices. At the end of the week, we also ensured notes on any deviations from the protocol and any problems encountered when downloading data off the camera or the GT9X Link devices were properly recorded in the participants' notes files. </p>"},{"location":"protocol/#sleep-protocol-data-collection","title":"Sleep Protocol Data Collection","text":"<p>The sleep protocol in the PAAWS study was an optional two-night protocol that took place during the FL procedure. In addition to wearing all sensors from the FL protocol, participants in the sleep study wore additional sensors for up to two nights to record polysomnography (PSG) sleep data during the participant\u2019s sleep in their own home. Labeled sleep/wake times and sleep stages data were obtained from the PSG data; the labels and the raw PSG data are released with the dataset. </p>"},{"location":"protocol/#sleep-sensors","title":"Sleep Sensors","text":"<p>To record PSG data, we used the Nox A1 PSG system. The system was configured to record thorax and abdomen RIP, nasal pressure, snore loudness, brain EEG, EKG, leg and chin EMG, EOG, and Sp02.  We configured the system so it did not record audio, but it was configured to record loudness (in dB) to determine snoring.</p>"},{"location":"protocol/#preparation-1","title":"Preparation","text":"<p>Before the arrival of a participant, researchers prepared for the sleep protocol by:</p> <ul> <li>Putting together a bag containing equipment for the participant to wear at home, which included:  </li> <li>The Nasal Cannula sensor  </li> <li>The Pulse oximeter sensor  </li> <li>Alcohol wipes  </li> <li>Extra tape for adhering the sensors  </li> <li>Initializing the Nox A1 PSG system with participants\u2019 info and synchronizing the time with the computer time using the Noxturnal Software.  </li> <li>Cleaning and preparing electroencephalogram (EEG), electromyography (EMG), and electrooculogram (EOG) electrodes and their corresponding wires.  </li> <li>Cutting out gauzes and tapes to the right size for use later.  </li> <li>Preparing a cup containing the NU Skin prep gel.  </li> <li>Preparing a cup containing 10-20 conductive gel.</li> </ul>"},{"location":"protocol/#sleep-sensor-locations-and-application","title":"Sleep Sensor Locations and Application","text":"<p>Participants were asked to arrive at the lab in the early to late evening prior to each night they participated in the Sleep protocol.. When each participant arrived, we further explained the sleep protocol and answered questions the participant had about the PSG data collection. Because the Sleep protocol took place during the FL protocol, during the Sleep protocol sensor set-ups, the participant was already wearing the FL sensors and had consented to participate in the study. In the Sleep protocol, we applied the majority of PSG sleep sensors to participants in the lab (detailed in In-Lab Sensor Application). Because actual sleep took place at home, however, and participants had to travel from the lab to home, some sensors were applied by the participant at home while on a video call with a researcher shortly before going to bed (detailed in At-Home Self Placement Application). </p> <p>PSG sensor application during the Sleep protocol followed the AAST Technical Guideline for Standard Polysomnography recommended by the American Academy of Sleep Medicine (AASM) to ensure high-quality recording. This included techniques to determine application sites and protocols to clean these sites to ensure optimal signal quality while minimizing discomfort. </p>"},{"location":"protocol/#in-lab-sensor-application","title":"In-Lab Sensor Application","text":"<p>We applied the following sensors during the approximately one-hour in-lab preparation session before each PSG-recording sleep night:</p> <ul> <li>Left and right leg electromyography (EMG).  </li> <li>10-lead head electroencephalogram (EEG) and electrooculogram (EOG), following the 10-20 EEG placement system.   </li> <li>EEG on: F3, F4, C3, C4, O1, O2, M1/A1, M2/A2.   </li> <li>Two EOG sensors near the left and right eyes. In our case, the EOG placement is  1\u00a0cm lateral and above the outer canthus of the right eye (E2) and 1\u00a0cm lateral and below (E1) the outer canthus of the left eye.  </li> <li>All electrodes are placed on the respective site on the head using the 10-20 electrode gel. To ensure that the electrodes will not fall off, we use additional tapes to secure the electrodes on the skin. For electrodes placed on the scalp, we instead use gauzes and extra electrode gel as needed, because tapes might not stick well to hair  </li> <li>Single-channel electrocardiogram in a lead II format.  </li> <li>Two respiratory inductance plethysmography belts on the chest and abdominal area.</li> </ul> <p>We performed and documented an impedance check of head EEG and EOG sensors to ensure proper placement as recommended by the manufacturer of the Nox A1 device. We re-applied any EOG or EEG sensors with poor impedance check, where the system did not detect any signal from these sensors.</p> <p>At the end of the in-lab sensor application, we scheduled a call for later that evening with the participant and sent the participant home with the additional bag and instructions we had prepared for them. When leaving the lab, participants were instructed to avoid vigorous physical activities, as these could increase the risk of wires becoming caught and dislodged, and to minimize activities that might induce sweating, which could compromise electrode adhesion. During the scheduled video call with the participant, we ensured all equipment was still functional and instructed participants how to apply the remaining sensors. All materials required to apply the remaining sensors at home were provided by us, as well as the necessary components of the Nox A1 system (e.g., the tablet computer).  </p>"},{"location":"protocol/#at-home-self-placement-sensors","title":"At Home Self-Placement Sensors","text":"<p>On the at-home video call with participants right before they went to bed during the Sleep protocol, following the AASM guidelines, we instructed participants to:</p> <ul> <li>Place the chin EMG electrodes.  </li> <li>Place the nasal cannula in their nostrils and secure the nasal cannula in place using the medical tape they were provided.   </li> <li>Place the pulse oximeter on the index finger of the non-dominant hand. They then secured the main body of the pulse oximeter device on the wrist using a provided elastic band. Additionally, they secured the \u201cfinger hood\u201d on the index finger using medical tape provided.</li> </ul> <p>After the video call with us to attach the remaining sensors, just before going to bed, participants started the PSG recording and then performed bio-calibration using the Noxturnal app on a provided Android tablet. They were instructed to reach out to the research team if they encountered any problems with this final step before they went to sleep. </p>"},{"location":"protocol/#morning-after-the-sleep-session","title":"Morning After the Sleep Session","text":"<p>Participants were instructed to take all sleep sensors off when they got out of bed and to put all equipment in a provided ziplock bag. During the day, at a convenient time, participants dropped off the ziplock bag, containing all the equipment, to a researcher. </p> <p>Upon receiving the equipment from the participant, we thoroughly cleaned all equipment, disposed of adhesives and one-time-use connectors, and downloaded the data off the Nox A1 device. We recorded any observed or participant-reported deviations from the protocol in the participant\u2019s notes file. </p>"},{"location":"protocol/#sensor-synchronization-procedures","title":"Sensor Synchronization Procedures","text":"<p>During the PAAWS protocol, we made various efforts to create synchronization points across data modalities to ensure that data across sensors could be time-synchronized. Using these points, we synchronize the raw signals of all sensor types in the PAAWS study; however, sensors had various timestamping constraints that may have impacted the precision of our syncing, including the following: </p> <ul> <li>During the FL protocol, Actigraph GT9X Link sensors ran for a week after initialization. They are known to drift by up to more than a second per day due to reliance on a crystal and recording data, assuming a perfect 80 Hz sampling rate (which in reality is not perfectly 80 Hz). In addition, when they are initialized, the GT9X Link sensors receive the time from the initializing computer, but the precision of the timestamp is only within 1-2 s of real time.  </li> <li>The PSG sensors receive the time from a tablet that is time-synchronized to a computer.   </li> <li>During the FL protocol, the camera receives the time from the laptop computer nightly, when it is connected each evening, which establishes its time from the internet.   </li> <li>The Polar sensor data is timestamped based on the GT9X Link sensor placed on top of the participant\u2019s right wrist.   </li> <li>The phone software, that records phone usage data, receives the time from the user\u2019s phone, which likely corrects its time regularly with the internet, but not guaranteed to be so. </li> </ul> <p>To establish the best possible raw data synchronization, manual synchronization points were created in the dataset (see above procedures for the synchronization steps). Using these manual synchronization points, we identified the corresponding points across various sensors and timestamps were adjusted accordingly. </p> <p>We used Signaligner Pro, a software capable of displaying a week of raw accelerometer data at full resolution, to visualize and identify these synchronization points (an example of which is shown in Figure 4) for each sensor at the start and end of the data collection session. For each sensor, we identified the synchronization point at the start and end of data collection. We then aligned all sensors to a reference sensor - randomly chosen among the available sensors.</p>"},{"location":"protocol/#figure-4.-an-example-of-the-accelerometer-signal-shape-resulting-from-a-box-drop.-notice-that-the-blue-line-(representing-the-z-axis)-shows-a-clear,-sharp-peak,-which-represents-when-the-box-hits-the-flat-surface-floor.","title":"Figure 4. An example of the accelerometer signal shape resulting from a box drop. Notice that the blue line (representing the Z axis) shows a clear, sharp peak, which represents when the box hits the flat surface floor.","text":"<p>In the event that the synchronization point from the box drop was not available for one or more sensors, a researcher attempted to use other distinguishing activities to do the synchronization (e.g., the Frankenstein walk or the hand clapping). Once a synchronization point was identified at the start and near the end of a data collection period, we assumed that all sensors had linear clock drift, and we used code to align the timestamps using linear interpolation. After this initial synchronization, a researcher visualized the newly synchronized data in Signaligner Pro to ensure that the synchronization process was completed correctly. The researcher checked if all synchronization points from all the GT9X Link sensors overlapped. </p> <p>For the Lab+SimFL sensor data, we were able to confirm that this synchronization process yields almost perfect synchronization across the data collection period because we had multiple sensors on the same limb and visually one can see near-perfect correspondence throughout the data collection period for those sensors.</p> <p>For the FL sensors, we confirmed that the two synchronization points from the box drop (see Figure 3) overlap perfectly for all sensors. During the course of the FL data collection, participants also perform synchronization moves twice per day (see During the FreeLiving Protocol). Examining these synchronization events revealed that although our synchronization was not perfect for these events, all sensors are synchronized to be within about 125 ms.</p>"},{"location":"protocol/#gt9x-sensor-synchronization-edge-cases","title":"GT9X Sensor Synchronization Edge Cases","text":"<p>In some cases in the Free-Living protocol, sensor data do not have easily identifiable box-drop synchronizations due to researcher error, participant error, or hardware failures. For instance, a hardware failure may include a Actigraph GT9X Link sensor stopping recording data early when the device battery became depleted; this behavior was unpredictable. When the participant reported the device battery did not last the entire protocol, a research assistant would provide the participant with a replacement sensor and noted the time the participant swapped to the new sensor for later data combination. The replacement sensor was synced normally with all the other sensors at the completion of the session, but we did not have a starting synchronization marker. In other cases, the participant did not report device failure and the sensor was returned without charge so we did not have an ending synchronization mark. In those cases, however, a research assistant  would use the synchronization moves that each participant should do twice per day  as a synchronization marker.</p> <p>At the conclusion of the data collection and after all GT9X Link sensors are synchronized, the data from the replacement sensor(s) (if used)were combined with data from the original sensor. A research assistant manually indicated the time when the first sensor is swapped with the second sensor and then, using a custom-made software we combined these two sensor streamed together, resulting in a single final data stream for the protocol with a potential gap of missing data from the sensor battery dying and being replaced. In some cases, we preemptively asked the participant to swap to a new sensor when the battery became low. When we combined these two data streams, we removed data from the original sensor stream past the swapping time and the leading data from the second sensor stream prior to the swapping time. If applicable, missing data are marked as \u201c,,\u201d entries in the data files \u2014 see The PAAWS Dataset Codebook.docx). Because, in edge cases, we could not identify clearly the start and end point synchronization movements in the signal, the signals are likely less precisely synchronized. </p>"},{"location":"protocol/#android-phone-sensor-synchronization","title":"Android Phone Sensor Synchronization","text":"<p>When a participant had their own Android phone, custom data collection software was installed on the phone. Because we also performed the box drop move with participants\u2019 phones, we were able to get the synchronization points by viewing the accelerometer data from the phone and comparing it with the accelerometer data from GT9X Link sensors. Using the synchronization points, we then adjusted the timestamp associated with each piece of phone data to ensure that the timestamp from phone data and phone acceleration data matches all other GT9X Link sensors.</p>"},{"location":"protocol/#sleep-data-synchronization","title":"Sleep Data Synchronization","text":"<p>We also synchronized the accelerometer data collected from the Nox A1 PSG system during the Sleep protocol with the GT9X Link data streams. We were not able to perform a \u201cbox shake\u201d with the Nox A1 system due to the nature of the device. Instead, because the Nox A1 system was secured to the participant\u2019s chest, we could use the accelerometer data from this \u201cchest-mounted\u201d sensor and the participant\u2019s right waist sensor to find highly correlated motions (e.g.,  postural changes such as lying on back to lying on the side) and synchronize the data streams with one another. Because there are no designed synchronization events, we had to assume that postural changes during sleep would yield similar acceleration changes at the same time on both the chest-mounted sensor and the waist sensor. Similar to the other sensor syncing protocol, we identified two synchronization points from postural changes during sleep, one at the start of the sleep session (in the evening) and one near the end of the sleep session (in the morning). Using these two synchronization points, we linearly interpolated the PSG data so that the final data stream was synchronized with the accelerometer data collected from the on-body ActiGraph GT9X sensors. </p> <p>The timestamps for all the other PSG sensors are synchronized with the chest accelerometer, so synchronizing the accelerometer allowed us to synchronize all sleep data with the GT9X Link data. Based on this procedure, the final PSG data and accelerometer data are synchronized to be within 1 s of each other. </p>"},{"location":"protocol/#video-synchronization","title":"Video Synchronization","text":"<p>To synchronize the video with the sensors, we used the video footage of the  synchronization moves that participants performed once near the beginning of the video and once near the end of the video (the hand clapping and knee pulling). Based on these visual markers, we adjusted the annotation labels\u2019 timestamps to match the acceleration signal.</p>"},{"location":"protocol/#video-merging","title":"Video Merging","text":"<p>During data collection, the camera stored video in chunks of up to ten minutes each (e.g., a 15-min of continuous recording will be stored as two 10-min and 5-min videos). We concatenated these chunks into a single video stream. Although participants were instructed to leave the camera running throughout the waking day and only cover it when they did not want to record, sometimes they turned the camera off during the day. In other cases, the research staff were troubleshooting a problem with data they observed and may have asked the participant to turn the camera on and off throughout the day. In the cases where the camera was turned off and on during the waking day, there was a gap between these ten-minute files. We used a custom-made software to determine the length of these gaps and fill in these gaps with a blacked-out video. Merged videos for a single waking day contain up to 16 hours of footage, with missing data blacked out. </p> <p>Video data are not available to researchers outside of the core research team due to participant privacy requirements. </p>"},{"location":"protocol/#labeling-of-synchronization-points","title":"Labeling of Synchronization Points","text":"<p>Participants performed a \u201csync move\u201d to determine a sync point between the sensor data and the video data (e.g., annotations) at the beginning of each protocol. This sync move consisted of five hand claps and five knee pulls in the Free-Living protocol and a \u201cFrankenstein walk\u201d in the SimFL+Lab protocol. In the case that participants did not perform a sync move (which may have happened in Free-Living protocol due to participant forgetfulness), the research assistant instead identified the timestamp when a participant changed from standing to sitting or sitting to standing, which resulted in clear change in acceleration in the Z axis in the thigh sensor. Using the merged video files and Media Player Classic, a researcher identified the video frame that the participant completed the synchronization activity. This timestamp was used to synchronize the annotations with the raw accelerometer data.</p>"},{"location":"protocol/#annotation-procedure","title":"Annotation Procedure","text":"<p>Annotators were recruited from the student body of Northeastern University. All students completed required human-subjects training (CITI) and lab safety training per university requirements. Annotators were paid by the hour and earned minimum wage. </p>"},{"location":"protocol/#annotator-training-procedure","title":"Annotator Training Procedure","text":"<p>Trainee annotators first studied the annotation taxonomy (described in detail in theThe PAAWS Dataset Codebook.docx). The taxonomy contains five label categories: physical activity type (PA Type), high-level behavior (HLB), contextual parameter (CP), and experimental situation (ES). Each specific label within any category is defined within the taxonomy. Annotators were expected to annotate labels for all five categories at the same time. Posture and physical activity types are mutually exclusive labels, meaning that the participant cannot simultaneously engage in two different physical activities or posture at the same time. High-level behavior and contextual parameters are non-mutually exclusive labels, meaning a participant could engage in multiple behaviors (i.e. eating while watching TV) and have multiple contextual modifiers (i.e. wearing a backpack and carrying groceries). The experimental situation label indicates whether the data are from the controlled lab session or part of the free living period. Annotators were expected to study all labels and categories carefully. After studying the labels, trainees completed a written exam; successful completion demonstrated their understanding of the annotation taxonomy.</p> <p>Annotators then practiced annotation using a set of 10 videos that were selected specifically for training using the custom-designed annotation software. These videos consisted of normal daily living activities and behaviors (e.g., cooking, driving, taking public transit, doing grocery shopping). To ensure the quality of new annotators, these videos were originally annotated by a researcher to obtain \u201cground truth\u201d annotation labels. The trainees' work was checked against these ground truth labels. Each annotator was required to achieve a minimum of 95% similarity on posture and physical activity labels and at least 85% on the high-level behavior labels. If this threshold was not met, a trained researcher discussed the discrepancies in light of the taxonomy and the trainee was asked to re-annotate. We calculated agreement between ground truth and a trainee\u2019s labels at a second-by-second granularity. The labels were considered to be in agreement if all the labels at a second were identical. The only exception to the agreement threshold test was for the physical activity label Puttering_Around. As defined in the taxonomy, this label is reserved for when a participant can be seen alternating between walking and standing (typically when engaging in some type of high-level behavior such as cooking or cleaning), such that labelling individual instances of walking and standing is difficult and ultimately infeasible. If the trainee produced more detailed annotations compared to ground truth (i.e. by labelling instances of Walking and Standing_With_Movement or Standing_Still instead of using the Puttering_Around label), and if the detailed labels were verified by a trained researcher, then the trainee was exempted from redoing the annotation despite the 95% similarity threshold not being met.</p> <p>The entire annotator training process took annotators between 5-10 hours. The differences in length can be attributed to some annotators initially making fewer mistakes while annotating the ten video training set and not needing to re-annotate these videos, while others needed to correct more mistakes to reach the agreement threshold.</p> <p>After annotation training was completed and annotator trainees reached out annotation threshold on the training set, they began annotating video data collected from participants in the PAAWS study. </p>"},{"location":"protocol/#annotation-procedures","title":"Annotation Procedures","text":"<p>Annotators annotated video using custom annotation software designed specifically for this annotation task. The software shows the current view and a \u201cnear future view\u201d so that annotators can most easily slow down and speed up the video without missing transitions and having to backtrack in the video (Figure 5). Annotators were encouraged to ask a supervising member of the research team if they were uncertain about how to label a situation. </p>"},{"location":"protocol/#figure-5.-the-custom-annotation-software-that-shows-both-the-\u201ccurrent\u201d-and-\u201cnear-future\u201d-views.-annotators-can-also-see-the-label-information-(including-the-label-timeline-and-the-currently-selected-label).","title":"Figure 5. The custom annotation software that shows both the \u201ccurrent\u201d and \u201cnear future\u201d views. Annotators can also see the label information (including the label timeline and the currently selected label).","text":"<p>Typical annotation sessions lasted three hours. Annotators were discouraged from scheduling longer annotation sessions due to fatigue. Annotator speed was computed and monitored. A \u201cfast\u201d annotator might work at a rate of about three hours of video time for one hour worked. Slower and newer annotators worked closer to about two hours of annotated time for one hour worked. </p> <p>After each annotation session, annotators used a quality control summary tool to identify possible erroneous labels based on the taxonomy (see Annotation Quality Control Procedure). </p> <p>Annotators were assigned videos to annotate on a rolling basis. That is, they would annotate video that happened to be available and unannotated when they were working rather than a single annotator annotating all the video from the same participant, and thus different portions of video from the same participant have typically been labeled by a mix of annotators. </p>"},{"location":"protocol/#annotation-edge-cases:-simfl+lab-annotation-video-perspective","title":"Annotation Edge Cases: SimFL+Lab Annotation Video Perspective","text":"<p>SimFL+Lab data were usually labeled using the third-person video recorded by the research staff member. There were six instances where the third-person recordings were corrupted or missing due to a technical problem with the camera, and there were 35 instances where a small portion of the third-person recordings were not sufficient to label the activity accurately due to poor camera handling (i.e., camera partially covered). In these instances, the first-person footage was used to annotate (or supplement the annotation) for the SimFL+Lab session. </p>"},{"location":"protocol/#annotation-data-quality-control-(qc)-procedure","title":"Annotation Data Quality Control (QC) Procedure","text":"<p>For video data, the \u201cgold-standard\u201d annotation protocol requires two independent annotators to annotate each video, with a third annotator (often a domain expert) resolving any disagreements. However, given the limited resources, it was only possible to have each video to be annotated by one person.  Because this is not the \u201cgold-standard\u201d, every annotation was verified using our QC protocol twice to identify possible annotation errors prior to data release: first by the initial annotator immediately after an annotation session, then by a team of research assistants when preparing the data for release. The QC protocol included automated tools and manual spot-checking to help identify possible issues. We fixed any identified issues that arose during this quality control process. </p>"},{"location":"protocol/#post-annotation-initial-annotator-qc-check","title":"Post-Annotation Initial Annotator QC Check","text":"<p>After each annotation session, the original annotator immediately ran a QC check on their annotations. Because of the nature of the SimFL+Lab and FL protocols, the QC check varied depending on which protocol was being annotated.</p> <p>The structure of the SimFL+Lab protocol allowed for immediate QC checking at the end of each annotator\u2019s session. Annotators ran software that detects (1) anomalies in label durations (i.e., unusually short or long activities), (2) instances an activity that only appeared an abnormal amount of times (e.g., Treadmill_3mph_Free_Walk appeared twice or Push_Ups_Lab appeared only once), and (3) if the labels intuitively make sense across the five categories in the annotation scheme. Given the rigid structure of the SimFL+Lab protocol, we know how long each activity should have lasted and any instances when the total time of an activity takes significantly more or less (\\~20%) time than specified in the SimFL+Lab protocol is reported to the annotator. Any true deviations from the SimFL+Lab protocol\u2014such as a very short/long instance of an activity or a missing activity\u2014are documented in the notes about that participant\u2019s data. Additionally, because we know how many times an activity should appear in the annotators\u2019 labels we reported instances where the current labels did not match the expected (e.g., Push_Ups_Lab only appears once because the break between sets is not annotated). Lastly, because we know the precise contexts that each activity in the SimFL+Lab protocol takes place in,  the software also verifies that the annotations across the scheme make sense together (e.g., if the PA Type is Treadmill_3mph_Drink_Lab the posture should be In_Position_Upright and the contextual parameter should be Holding_Drink). Any instances where the labels did not match were flagged to the annotator, who corrected these discrepancies or documented them in the participant\u2019s note file.  </p> <p>Because the Free-Living data activities are unconstrained, the automatic post-annotation QC checks were also less constrained. The QC software reported (1) an automatic check to ensure the mapping between the HLB, PA type, and posture makes sense, (2) any anomalous length labels (defined as any label shorter than 5 s and any label longer than 60 min), and (3) any label that occurs only once in a dataset. Additionally, annotators were shown a report listing all the labels they used, their durations, the number of instances that labeled appeared in their annotations.  Annotators are expected to review all flagged instances and resolve any problems or document anomalies in the participants notes. Finally, annotators sign off virtually to ensure all quality control protocols have been followed before finalizing their labels.</p>"},{"location":"protocol/#final-annotation-quality-assurance-procedure","title":"Final Annotation Quality Assurance Procedure","text":"<p>After the entire SimFL+Lab or FL dataset for a participant had been labeled by the annotators, the research team performed additional quality assurance checks to ensure all previous annotation and quality control protocols were conducted accurately. </p> <p>On the SimFL+Lab annotations, we reran the initial annotator QC software, then two separate researchers verified all flagged instances were resolved or documented accordingly.  </p> <p>On the FL annotations, a researcher performed a visual inspection of the labels for each day of a participant\u2019s data, while taking note of the total time spent in each label across the FL procedure. This check allows us to spot labels that deviate from an individual\u2019s normal behaviors. In addition to the spot-check, two researchers re-ran the FL QC software, verified all the flagged instances, and ensured anomalies (if any) were correctly documented. </p>"},{"location":"protocol/#overall-data-processing-and-quality-control","title":"Overall Data Processing and Quality Control","text":"<p>After all data streams were synchronized with each other and the data was annotated, additional automated and manual quality control checks were performed on the raw sensor data.  Any issues found during the QC procedure were either fixed or documented accordingly.</p>"},{"location":"protocol/#raw-accelerometer-data-anomaly-detection","title":"Raw Accelerometer Data Anomaly Detection","text":"<p>To quickly identify potential issues with the raw accelerometer data, a quality control tool\u2014 dveloped for NHANES\u2014was used to identify anomalous accelerometer activity by automatically flagging obviously faulty signals, such as a signal with impossible g values (constant g values for all axes for an extended period), missing values (extended periods with no data or perfectly zero acceleration), or impossible spikes within the data (extended period where there are fluctuations exceeding eleven spikes per second). When the QC tool flagged a segment of data, the data were loaded into Signaligner Pro and manually inspected by a researcher familiar with accelerometer data. While the quality control tool flagged some anomalies (e.g., constant zero acceleration at recording boundaries or gaps within the data), manual inspection confirmed these were expected patterns rather than data corruption, with no actual corruption found across the dataset.</p>"},{"location":"protocol/#simfl-+-lab-data-sensor-orientation-automated-quality-control-check","title":"SimFL + Lab Data Sensor Orientation Automated Quality Control Check","text":"<p>Because the SimFL+Lab protocol was (relatively) short and prescribed, we knew the intended orientation of all sensors during all activities. Additionally, we had taken sensor placement photos at the beginning of the protocol. When preparing the data for release, we manually inspected all of the sensor placement photos. From the photos, the only sensor orientation issue that occurred was a 180-degree rotation about the z axis. This occurred for 20 of the \\~3k sensors placed throughout the SimFL+Lab protocol. All sensor orientation issues were documented in the overall data summary note (detailed in The PAAWS Dataset Codebook.docx).</p>"},{"location":"protocol/#fl-activity-detection-anomaly-checking","title":"FL Activity Detection Anomaly Checking","text":"<p>Although we have performed an extensive manual review for FL annotation, we could miss incorrectly labeled instance in the FL dataset. Therefore, we are actively working on developing additional automated checks for anomalous data or labels. We are exploring the use of an activity prediction model to highlight potential mismatches between the data and labels that might prompt researchers to review the flagged annotation instance more closely. We are constraining the problem to training and predicting on more common activities in daily living, including standing, walking, and sedentary activities. We use a ResNet-like architecture using accelerometer data from both the thigh and the right wrist sensors using 10 s non-overlapping windows. To further account for activity imbalance in the dataset (which is highly skewed toward sedentary behavior), we use a custom training approach that gives an equal number of windows for each activity in each batch. For each participant in the currently released dataset, we trained an activity recognition model using data collected from the other 19 participants and then used that model to flag incorrectly annotated instances. Mismatches longer than sixty seconds are highlighted for manual footage review, where a trained researcher can use our annotation software to edit the label as needed.</p>"},{"location":"protocol/#simfl+lab-final-sensor-and-label-quality-assurance-procedure","title":"SimFL+Lab Final Sensor and Label Quality Assurance Procedure","text":"<p>After the dataset was collected and all previous quality control measures are applied, a trained researcher manually reviews the signal and annotated labels using Signaligner. Researchers inspect all twenty-one accelerometer signals, looking for acceleration signal that deviates from normal expected signal given an activity label (e.g., a standing label should have significant differences to a sitting label when examining the thigh accelerometer, sensors on the same limb should show generally similar signals throughout the protocol). If the researchers found any issues, they referred to the video recorded during the SimFL+Labsession to corroborate the anomaly or fix the issue. If necessary, they  documented the issue accordingly.</p>"},{"location":"protocol/#free-living-final-sensor-and-label-quality-assurance-procedure","title":"Free-Living Final Sensor and Label Quality Assurance Procedure","text":"<p>After the data has been collected and processed, a trained researcher did a manual inspection of the accelerometer signals and labels to ensure data were synced correctly. Any issues (unsynced accelerometer signal or labels that appear to \u201cdrift\u201d) are carefully re-examined using the original FL video, and the syncing process was repeated as needed.</p>"}]}